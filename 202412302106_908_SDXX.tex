% 深度学习（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Deep_learning}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/b06d12296b7d8e2d.png}
\caption{在深度学习中以多层抽象表示图像[1]} \label{fig_SDXX_1}
\end{figure}
深度学习是机器学习的一个子领域，专注于利用神经网络执行分类、回归和表示学习等任务。该领域受到生物神经科学的启发，核心在于将人工神经元堆叠成多层，并通过“训练”使其能够处理数据。“深度”一词指的是网络中使用了多层结构，这些层数从三层到几百甚至几千层不等。深度学习的方法可以是监督学习、半监督学习或无监督学习。[2]

常见的深度学习网络架构包括全连接网络（Fully Connected Networks）、深度信念网络（Deep Belief Networks）、循环神经网络（Recurrent Neural Networks）、卷积神经网络（Convolutional Neural Networks）、生成对抗网络（Generative Adversarial Networks）、Transformer以及神经辐射场（Neural Radiance Fields）。这些架构已应用于计算机视觉、语音识别、自然语言处理、机器翻译、生物信息学、药物设计、医学图像分析、气候科学、材料检测以及棋盘游戏程序等领域，并在许多情况下取得了与人类专家相当甚至超越的表现。[3][4][5]

早期形式的神经网络受到生物系统中信息处理和分布式通信节点的启发，特别是人脑。然而，当前的神经网络并不旨在模拟生物体的大脑功能，在这一方面通常被认为是低质量的模型。[6]
\subsection{概述}
大多数现代深度学习模型基于多层神经网络，例如卷积神经网络和Transformer，但它们也可能包含命题公式或潜变量，这些变量在深度生成模型中按层次组织，如深度信念网络和深度玻尔兹曼机中的节点。[7]

从根本上说，深度学习指的是一类机器学习算法，其特点是使用层次化的结构将输入数据逐步转换为更加抽象和复合的表示。例如，在图像识别模型中，原始输入可能是图像（表示为像素张量）。第一层表示可能试图识别基本形状（如线条和圆形），第二层可能组合和编码边缘排列，第三层可能编码鼻子和眼睛，第四层可能识别出图像中包含一张人脸。

深度学习的一个关键特点是，模型可以自主学习最佳特征及其所在的层级。在深度学习出现之前，机器学习技术通常需要通过手动设计特征工程来将数据转换为更适合分类算法操作的形式。而在深度学习方法中，特征不是手动设计的，模型会从数据中自动发现有用的特征表示。这并不意味着无需手动调整，例如，层数和每层大小的变化会提供不同程度的抽象。[8][2]

“深度学习”中的“深度”指的是数据被转换的层数。更确切地说，深度学习系统具有较大的信用分配路径（CAP，Credit Assignment Path）深度。CAP是从输入到输出的一系列转换过程，描述了输入和输出之间的潜在因果关系。对于前馈神经网络，CAP深度等于网络的深度，即隐藏层的数量加一（因为输出层也被参数化）。对于信号可能在某一层多次传播的循环神经网络，CAP深度潜在无限。[9] 虽然没有统一公认的深度门槛来区分浅层学习与深度学习，但大多数研究者认为深度学习的CAP深度大于2。研究表明，CAP深度为2的模型在理论上是一个通用逼近器，能够模拟任何函数。[10] 超过这一深度，更多的层不会提高网络作为函数逼近器的能力。然而，深度模型（CAP > 2）能够比浅层模型提取出更好的特征，因此额外的层数有助于有效地学习特征。

深度学习架构可以通过逐层的贪婪方法构建。[11] 深度学习能够解开抽象，提取出哪些特征有助于提升性能。[8]

深度学习算法可以应用于无监督学习任务。这是一个重要的优势，因为无标签数据比有标签数据更为丰富。可以通过无监督方式训练的深度结构包括深度信念网络等。[8][12]

“深度学习”这一术语由Rina Dechter在1986年引入机器学习领域，[13] 并由Igor Aizenberg及其同事于2000年引入人工神经网络领域，最初用于描述布尔阈值神经元。[14][15] 不过，其出现的历史显然更加复杂。[16]
\subsection{解释}
深度神经网络通常通过\textbf{通用逼近定理}[17][18][19][20][21]或\textbf{概率推断}[22][23][8][9][24]进行解释。

经典的\textbf{通用逼近定理}涉及具有单个有限大小隐藏层的前馈神经网络逼近连续函数的能力。[17][18][19][20] 1989年，George Cybenko首次证明了具有S形激活函数的前馈网络的通用逼近能力，[17] 这一结果在1991年被Kurt Hornik推广到多层前馈网络架构。[18] 最近的研究还表明，通用逼近定理同样适用于诸如Kunihiko Fukushima提出的修正线性单元（ReLU）等无界激活函数。[25][26]

针对深度神经网络的通用逼近定理则关注网络的宽度有限，但深度可以增加的情况下的逼近能力。Lu等人[21]证明，如果深度神经网络的宽度严格大于输入维度，且激活函数为ReLU，那么该网络可以逼近任何勒贝格可积函数；如果宽度小于或等于输入维度，则深度神经网络不具有通用逼近能力。

\textbf{概率解释}[24]来源于机器学习领域，涉及推断[23][7][8][9][12][24]以及与训练和测试相关的优化概念，分别对应于拟合和泛化。更具体地说，概率解释将激活非线性视为累积分布函数。[24] 概率解释促成了在神经网络中引入\textbf{dropout}作为正则化方法。这一解释由Hopfield、Widrow和Narendra等研究人员提出，并通过Bishop等人的综述文章得到推广。[27]
\subsection{历史}
\subsubsection{1980年之前}
人工神经网络（ANN）分为两种类型：\textbf{前馈神经网络（FNN）}或\textbf{多层感知机（MLP）}和\textbf{循环神经网络（RNN）}。RNN的连接结构中包含循环，而FNN则没有。

1920年代，\textbf{威廉·伦茨（Wilhelm Lenz）}和\textbf{恩斯特·伊辛（Ernst Ising）}提出了\textbf{伊辛模型（Ising model）}，[28][29] 其本质上是一种非学习型RNN架构，由类神经元的阈值元素组成。1972年，\textbf{天利俊一（Shun'ichi Amari）}将这一架构改造成自适应的。[30][31] 他的学习型RNN在1982年由\textbf{约翰·霍普菲尔德（John Hopfield）}重新发表。[32] 其他早期的循环神经网络包括\textbf{中野薰（Kaoru Nakano）}在1971年发表的模型。[33][34] 早在1948年，\textbf{艾伦·图灵（Alan Turing）}就已经在未发表的论文《智能机器》（Intelligent Machinery）中提出了与人工进化和学习型RNN相关的思想。[35][31]

1958年，\textbf{弗兰克·罗森布拉特（Frank Rosenblatt）}提出了感知机（Perceptron），这是一个包含三层的MLP：输入层、具有随机权重的隐藏层（不参与学习）和输出层。他在1962年的书中进一步介绍了感知机的变体和计算机实验，包括一种四层感知机的版本，其“终端前网络”（preterminal networks）具有自适应权重。[37] 书中引用了\textbf{R.D. Joseph}于1960年提出的一个类似系统[38]，但Joseph的学习算法并不实用，最终被遗忘。

第一个可用的深度学习算法是1965年\textbf{亚历克谢·伊瓦赫宁科（Alexey Ivakhnenko）}和Lapa提出的\textbf{数据处理组方法（Group Method of Data Handling, GMDH）}，它可以训练任意深度的神经网络。[39] 1971年的一篇论文描述了用这种方法训练的八层深度网络。[41] 该方法通过逐层回归分析进行训练，并使用单独的验证集剪枝多余的隐藏单元。节点的激活函数是柯尔莫哥洛夫-加博尔多项式（Kolmogorov-Gabor polynomials），因此这些是最早的带有乘性单元或“门”的深度网络。[31]

第一个使用\textbf{随机梯度下降（Stochastic Gradient Descent, SGD）}训练的多层感知机（MLP）由\textbf{天利俊一}于1967年提出。[43] 他的学生Saito的计算机实验显示，一个五层MLP通过两个可调节层学会了非线性可分模式的内部表示。[31] 随着硬件和超参数调节的发展，端到端的随机梯度下降已成为当前主流的训练技术。

1969年，\textbf{福岛邦彦（Kunihiko Fukushima）}引入了\textbf{修正线性单元（ReLU, Rectified Linear Unit）}激活函数。[25][31] ReLU已成为深度学习中最流行的激活函数。[44]

卷积神经网络（CNN）的深度学习架构，包含卷积层和下采样层，起源于1979年\textbf{福岛邦彦}提出的新认知机（Neocognitron），尽管当时未使用反向传播进行训练。[45][46]

\textbf{反向传播（Backpropagation）}是一种高效应用由\textbf{戈特弗里德·威廉·莱布尼茨（Gottfried Wilhelm Leibniz）}于1673年提出的链式法则的技术，用于可微节点组成的网络。术语“误差反向传播”（Back-propagating errors）由\textbf{罗森布拉特}在1962年引入，[37] 但他并未实现该方法。\textbf{Henry J. Kelley}在1960年提出了控制理论背景下的连续版本反向传播。[48] 现代形式的反向传播首次由\textbf{Seppo Linnainmaa}在1970年的硕士论文中发表。[49][50][31] \textbf{G.M. Ostrovski}等人在1971年重新发表了该方法。[51][52] \textbf{Paul Werbos}在1982年将反向传播应用于神经网络，[53] 但他的1974年博士论文中尚未描述该算法。[52] 1986年，\textbf{David E. Rumelhart}等人推广了反向传播，但未引用最初的研究。[55][56]
\subsubsection{1980年代至2000年代}
时延神经网络（TDNN）：1987年，Alex Waibel 引入了时延神经网络（TDNN），将卷积神经网络（CNN）应用于音素识别。它使用了卷积、权重共享和反向传播。[57][58]CNN早期应用：1988年，Wei Zhang将反向传播训练的CNN用于字母识别。[59] 1989年，Yann LeCun等人开发了LeNet，用于识别邮件上的手写邮政编码，训练耗时3天。[60]1990年，Wei Zhang在光学计算硬件上实现了CNN。[61] 1991年，CNN被应用于医学图像分割[62]和乳腺癌检测。[63] 1998年，LeNet-5是一个7层CNN，用于分类手写数字，并被多家银行用于识别支票上的手写数字。[64]  

RNN在1980年代得到了进一步发展，主要用于序列处理。展开后的RNN在数学上类似于深度前馈层。[28][30] 两个早期的关键RNN模型：Jordan网络（1986）[65]和Elman网络（1990）[66]，被用于认知心理学问题的研究。

1980年代，反向传播在长信用分配路径上的表现不佳。1991年，Jürgen Schmidhuber提出了一种分层RNN，通过自监督学习逐层预训练，每层RNN尝试预测自身的下一个输入。[67][68]  1993年，这种神经历史压缩器解决了一个“非常深度学习”任务，涉及1000多层展开的RNN。[69]  

1991年，Sepp Hochreiter在毕业论文中提出了LSTM，并分析了梯度消失问题。[70][71] 1995年，LSTM被正式发表。[72] LSTM能够处理需要数千离散时间步的长期记忆任务。现代LSTM架构于1999年引入“遗忘门”，成为标准RNN架构。[73]  

生成对抗网络的雏形：1991年，Schmidhuber提出了“对抗神经网络”，其中两个网络以零和博弈形式竞争。[74][75] 这一原理在2014年被用于开发生成对抗网络（GANs）。[76]  

无监督学习模型：受统计力学的启发，Terry Sejnowski、Peter Dayan 和 Geoffrey Hinton等人开发了玻尔兹曼机、受限玻尔兹曼机、赫姆霍兹机及其“唤醒-睡眠”算法。[77][78][79][80] 这些模型设计用于深度生成模型的无监督学习，但与反向传播相比计算成本更高。 生物信息学的早期应用：1988年的网络成为蛋白质结构预测的最新成果，这是深度学习在生物信息学中的早期应用。[82]  

ANN的探索：ANN（包括RNN）在语音识别中的浅层和深层学习已被研究多年。[83][84][85] 然而，早期方法未能超越基于生成模型的GMM-HMM技术。[86] 主要困难包括梯度消失[70]和神经预测模型中时间相关性较弱。[87][88]  

例外进展：1990年代末，SRI International在美国NSA和DARPA资助下，研究语音和说话人识别。1998年，Larry Heck领导的团队在NIST说话人识别基准中取得了显著成功，并在Nuance Verifier中部署，这是深度学习的首次重大工业应用。[89][91]  原始特征的探索：1990年代末，深度自编码器首次在“原始”语谱图或线性滤波特征上表现出优越性，超越了传统的梅尔倒谱特征。[90] 随后，基于原始语音波形的深度学习在大规模任务中取得了优异表现。[92]  