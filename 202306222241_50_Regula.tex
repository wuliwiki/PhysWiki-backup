% 正则化
% keys 正则化

\textbf{正则化}（Regularization）是机器学习中用于减少泛化误差（测试误差），从而缓解过度拟合的设计策略。当使用正则化策略减少泛化误差时，可能会增大训练误差。

\textbf{参数范数惩罚}是最常用的正则化策略之一。传统机器学习方法就有很多使用，而在当今的深度学习中也应用广泛。参数范数惩罚的主要思想是给目标函数$J$添加一个参数范数惩罚项$\Omega(\theta)$，限制模型的学习能力，从而减少过度拟合的发生。设$J'$为正则化后的目标函数，则有：
\begin{equation}
J'(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)
\end{equation}
其中，$\alpha\in[0,\infty)$是权衡范数惩罚项$\Omega$和标准目标函数$J(X;\theta)$相对贡献的超参数。将$\alpha$设为$0$表示没有正则化。

\subsection{$L^2$参数正则化}

$L^2$参数正则化指的是用参数的2范数作为惩罚项。


\subsection{$L^1$参数正则化}