% 人工神经网络（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/9fddb6b4ea5a9fd3.png}
\caption{人工神经网络是一个互相连接的节点群，灵感来源于大脑中神经元的简化模型。在这里，每个圆形节点代表一个人工神经元，箭头代表从一个人工神经元的输出到另一个人工神经元输入的连接。} \label{fig_RGSJ_1}
\end{figure}
在机器学习中，神经网络（也称为人工神经网络或神经网，缩写为ANN或NN）是一种受到动物大脑生物神经网络结构和功能启发的模型。[1][2]

一个人工神经网络由连接的单元或节点组成，这些节点被称为人工神经元，粗略地模拟大脑中的神经元。这些神经元通过边（连接）相互连接，模拟大脑中的突触。每个人工神经元接收来自连接神经元的信号，然后处理这些信号并将结果传送给其他连接的神经元。这个“信号”是一个实数，每个神经元的输出通过某个非线性函数计算，该函数作用于输入的和，这个过程被称为激活函数。每个连接的信号强度由一个权重决定，权重会在学习过程中调整。

通常，神经元会被聚合成层。不同的层可能对其输入执行不同的变换。信号从第一层（输入层）传输到最后一层（输出层），可能会经过多个中间层（隐藏层）。如果一个网络至少有两个隐藏层，通常称其为深度神经网络。[3]

人工神经网络被用于各种任务，包括预测建模、自适应控制和解决人工智能中的问题。它们能够从经验中学习，并能够从复杂且看似不相关的信息集中推导结论。
\subsection{训练}
神经网络通常通过经验风险最小化进行训练。这种方法基于优化网络参数，以最小化预测输出与给定数据集中的实际目标值之间的差异或经验风险的理念。[4] 基于梯度的方法，如反向传播，通常用于估计网络的参数。[4] 在训练阶段，人工神经网络通过标记的训练数据进行学习，通过迭代更新参数以最小化定义的损失函数。[5] 这种方法使得网络能够对未见过的数据进行泛化。
\subsection{历史}  
\subsubsection{早期工作}  
今天的深度神经网络基于200多年前统计学的早期工作。最简单的前馈神经网络（FNN）是一个线性网络，它由一层输出节点组成，节点使用线性激活函数；输入通过一系列权重直接馈送到输出。在每个节点上，输入和权重的乘积之和会被计算出来。通过对这些计算的输出与给定目标值之间的均方误差进行最小化，调整权重。这种技术已经有两个多世纪的历史，被称为最小二乘法或线性回归。它由勒让德（1805年）和高斯（1795年）用于预测行星运动，通过找到一组点的最佳线性拟合。[7][8][9][10][11]  

历史上，像冯·诺依曼模型这样的数字计算机通过执行显式指令并通过多个处理器访问内存来操作。另一方面，一些神经网络起源于试图通过联结主义框架模拟生物系统中的信息处理。与冯·诺依曼模型不同，联结主义计算不将内存和处理分开。  

沃伦·麦卡洛克和沃尔特·皮茨（1943年）考虑了一个非学习型的神经网络计算模型。[13] 这个模型为神经网络研究分裂成两种不同的方向奠定了基础。一种方向专注于生物过程，而另一种方向则专注于神经网络在人工智能中的应用。

在20世纪40年代末，D.O. Hebb[14] 提出了一个基于神经可塑性机制的学习假设，这个假设后来被称为赫布学习（Hebbian learning）。它被用于许多早期的神经网络中，例如Rosenblatt的感知器和霍普菲尔德网络。Farley和Clark[15]（1954年）使用计算机模拟了一个赫布网络。其他神经网络计算机器由Rochester、Holland、Habit和Duda（1956年）创建。[16]  

1958年，心理学家Frank Rosenblatt描述了感知器，这是一种最早实现的人工神经网络之一，[17][18][19][20] 由美国海军研究办公室资助。[21] R.D. Joseph（1960年）[22] 提到Farley和Clark（1956年）开发的早期感知器类设备：[10] "麻省理工学院林肯实验室的Farley和Clark实际上在感知器类设备的开发上先于Rosenblatt。" 然而，他们“放弃了这个课题。”感知器引发了公众对人工神经网络研究的热情，促使美国政府大幅增加资金。这为计算机科学家对感知器能够模拟人类智能的乐观预期提供了支持，进一步推动了“人工智能的黄金时代”。[23]  

最初的感知器没有自适应的隐藏单元。然而，Joseph（1960年）[22] 也讨论了具有自适应隐藏层的多层感知器。Rosenblatt（1962年）[24]: 第16节 引用并采纳了这些想法，同时也给出了H.D. Block和B.W. Knight的工作。然而，这些早期的努力并未导致隐藏单元的有效学习算法，也就是深度学习的实现未能成功。
\subsubsection{1960年代和1970年代的深度学习突破}
在1960年代和1970年代，人工神经网络（ANNs）进行了基础研究。第一个有效的深度学习算法是数据处理组方法（Group Method of Data Handling），这是一个用于训练任意深度神经网络的方法，由Alexey Ivakhnenko和Lapa于苏联（1965年）提出。他们将其视为一种多项式回归方法，[25] 或者说是Rosenblatt感知器的推广。[26] 1971年的一篇论文描述了一个由这种方法训练的八层深度网络，[27] 该方法基于通过回归分析逐层训练的方式。通过使用单独的验证集修剪冗余的隐藏单元。由于节点的激活函数是Kolmogorov-Gabor多项式，这些也成为了第一个具有乘法单元或“门”的深度网络。[10]

第一个通过随机梯度下降（SGD）训练的深度学习多层感知器（MLP）由Shun'ichi Amari于1967年发布。[29] 在Amari的学生Saito进行的计算机实验中，一个具有五层的多层感知器（MLP）通过修改两层的方式学习了内部表示，用于对非线性可分模式类别进行分类。[10] 随着硬件和超参数调优的发展，端到端的随机梯度下降目前已成为主流的训练技术。

1969年，Kunihiko Fukushima引入了ReLU（修正线性单元）激活函数。[10][30][31] 修正器成为了深度学习中最流行的激活函数。[32]

尽管如此，在美国的研究在Minsky和Papert（1969年）的工作之后停滞不前，[33] 他们强调基础感知器无法处理异或（exclusive-or）电路。这个洞察对Ivakhnenko（1965年）和Amari（1967年）的深度网络并不适用。

1976年，迁移学习在神经网络学习中被引入。[34][35]

深度学习架构用于卷积神经网络（CNNs），包括卷积层、降采样层和权重复制，始于Kunihiko Fukushima于1979年引入的Neocognitron，尽管该网络并未通过反向传播进行训练。[36][37][38]
\subsubsection{反向传播}
反向传播是一种有效的链式法则应用，由戈特弗里德·威廉·莱布尼茨（Gottfried Wilhelm Leibniz）于1673年提出[39]，用于可微节点的网络。术语“反向传播误差”最早是由Rosenblatt在1962年提出的，[24] 但当时他并不知道如何实现这一过程，尽管亨利·J·凯利（Henry J. Kelley）在1960年在控制理论的背景下已经有了反向传播的连续先驱[40]。1970年，塞波·林奈马（Seppo Linnainmaa）在他的硕士论文中发表了现代形式的反向传播（1970年）[41][42][10]。G.M. 奥斯特罗夫斯基（G.M. Ostrovski）等人在1971年重新发表了这一工作[43][44]。保罗·韦尔博斯（Paul Werbos）在1982年将反向传播应用于神经网络[45][46]（他的1974年博士论文，1994年再版的书籍[47]中并未描述该算法[44]）。1986年，大卫·E·鲁梅哈特（David E. Rumelhart）等人普及了反向传播，但没有引用原始的工作[48]。
\subsubsection{卷积神经网络}
1979年，福岛邦彦（Kunihiko Fukushima）提出的卷积神经网络（CNN）架构[36]，同时引入了最大池化（max pooling）[49]，这一程序成为CNN中常用的下采样方法。卷积神经网络（CNN）已成为计算机视觉领域的重要工具。

时延神经网络（TDNN）由亚历克斯·韦博尔（Alex Waibel）于1987年提出，旨在将CNN应用于音素识别。它使用了卷积、权重共享和反向传播技术[50][51]。1988年，张伟（Wei Zhang）将一个经过反向传播训练的CNN应用于字母识别[52]。1989年，扬·勒昆（Yann LeCun）等人创建了一个名为LeNet的CNN，用于识别邮寄物品上的手写邮政编码。训练过程耗时3天[53]。1990年，张伟将CNN实现于光学计算硬件上[54]。1991年，CNN被应用于医学影像中的物体分割[55]以及乳腺癌的乳腺X光检测[56]。LeNet-5（1998），由扬·勒昆等人提出的一个7层CNN，用于对数字进行分类，被几家银行应用于识别支票上手写的数字，数字图像为32×32像素[57]。

自1988年起[58][59]，神经网络的使用在蛋白质结构预测领域带来了变革，尤其是在第一个级联网络通过多重序列比对生成的轮廓（矩阵）进行训练时[60]。
\subsubsection{循环神经网络}
RNN（循环神经网络）的一个起源是统计力学。1972年，天野俊一（Shun'ichi Amari）提出通过Hebbian学习规则修改Ising模型的权重，作为联想记忆的模型，并加入了学习的成分[61]。这一概念由约翰·霍普菲尔德（John Hopfield）于1982年推广为霍普菲尔德网络[62]。RNN的另一个起源是神经科学。术语“recurrent”（循环）用于描述解剖学中的环路结构。1901年，卡哈尔（Cajal）在小脑皮层观察到“循环半圆形”结构[63]。赫布（Hebb）则将“回响电路”作为短期记忆的解释[64]。麦卡洛克和皮茨（McCulloch and Pitts，1943）在论文中考虑了包含循环的神经网络，并指出此类网络的当前活动可以受到远古历史中活动的影响[12]。

1982年，提出了一种名为**Crossbar Adaptive Array**的循环神经网络（而非多层感知器结构），其使用了从输出到监督（教师）输入的直接递归连接。除了计算行动（决策），它还计算了结果情境的内部状态评估（情感）。通过消除外部监督，该网络引入了神经网络中的自我学习方法。

在1980年代初期的认知心理学期刊《American Psychologist》中，开展了一场关于认知与情感之间关系的辩论。1980年，扎琼茨（Zajonc）表示情感是首先计算的，并且独立于认知，而拉扎鲁斯（Lazarus）则在1982年指出，认知是首先计算的，并且与情感不可分离[67][68]。1982年，Crossbar Adaptive Array提出了一种神经网络模型来说明认知-情感关系[65][69]。这是人工智能系统——一种循环神经网络——在认知心理学领域所贡献的一个例子。

两项早期有影响力的工作是乔丹网络（Jordan Network，1986）和埃尔曼网络（Elman Network，1990），它们应用RNN研究认知心理学。

在1980年代，反向传播算法在深层RNN上表现不佳。为了克服这一问题，1991年，Jürgen Schmidhuber提出了“神经序列分块器”（neural sequence chunker）或“神经历史压缩器”（neural history compressor）[70][71]，该方法引入了自我监督预训练（ChatGPT中的“P”）和神经知识蒸馏的重要概念[10]。1993年，一个神经历史压缩系统解决了一个需要超过1000层递归展开的“非常深的学习”任务[72]。

1991年，Sepp Hochreiter的学位论文[73]识别并分析了梯度消失问题[73][74]，并提出了递归残差连接来解决该问题。他与Schmidhuber一起提出了长短期记忆（LSTM），在多个应用领域创造了准确度记录[75][76]。但这还不是现代版本的LSTM，现代LSTM需要遗忘门（forget gate），该门在1999年被引入[77]。它成为了RNN架构的默认选择。

在1985到1995年间，受到统计力学启发，Terry Sejnowski、Peter Dayan、Geoffrey Hinton等人开发了多个架构和方法，包括Boltzmann机[78]、限制玻尔兹曼机[79]、赫尔姆霍兹机[80]和唤醒-睡眠算法[81]。这些方法设计用于深度生成模型的无监督学习。
\subsubsection{深度学习}
在2009到2012年间，人工神经网络（ANN）开始在图像识别竞赛中获奖，并在各种任务上接近人类水平的表现，最初是在模式识别和手写识别方面[82][83]。2011年，Dan Ciresan、Ueli Meier、Jonathan Masci、Luca Maria Gambardella和Jürgen Schmidhuber团队提出的CNN模型DanNet[84][85]首次在视觉模式识别竞赛中取得超人类表现，超越传统方法三倍[38]。随后它继续赢得了更多竞赛[86][87]。他们还展示了在GPU上使用最大池化CNN显著提高了性能[88]。

2012年10月，Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton提出的AlexNet[89]在ImageNet大型竞赛中以显著的优势战胜了浅层机器学习方法。随后的增量改进包括Karen Simonyan和Andrew Zisserman提出的VGG-16网络[90]以及Google的Inceptionv3[91]。

2012年，吴恩达（Ng）和Dean创造了一个网络，仅通过观看无标签图像，便学习识别更高层次的概念，例如猫[92]。无监督预训练和来自GPU和分布式计算的计算能力提升，使得能够使用更大的网络，特别是在图像和视觉识别问题中，这被称为“深度学习”[5]。

2013年，径向基函数和小波网络被引入。这些网络展示了最佳逼近性质，并已应用于非线性系统识别和分类问题[93]。

生成对抗网络（GAN）（Ian Goodfellow等人，2014）[94]在2014到2018年期间成为生成建模领域的技术前沿。GAN原理最早由Jürgen Schmidhuber于1991年提出，他称之为“人工好奇心”：两个神经网络通过零和博弈的形式相互竞争，其中一个网络的获益是另一个网络的损失[95][96]。第一个网络是生成模型，它建模输出模式的概率分布。第二个网络通过梯度下降学习预测环境对这些模式的反应。Nvidia的StyleGAN（2018）[97]基于Tero Karras等人提出的Progressive GAN[98]，成功实现了优质图像生成。这里，GAN生成器以金字塔的形式从小到大逐步增长。GAN的图像生成取得了广泛成功，并引发了关于深度伪造（deepfakes）的讨论[99]。自此以来，扩散模型（2015）[100]在生成建模中超越了GAN，出现了DALL·E 2（2022）和Stable Diffusion（2022）等系统。

2014年，技术前沿是训练具有20到30层的“非常深的神经网络”[101]。堆叠过多的层导致训练准确度急剧下降[102]，即“退化”问题[103]。2015年，提出了两种训练非常深网络的技术：高速公路网络（highway network）在2015年5月发布[104]，残差神经网络（ResNet）在2015年12月发布[105][106]。ResNet类似于开门的高速公路网络。

在2010年代，seq2seq模型被开发出来，并加入了注意力机制。2017年，这导致了现代Transformer架构的提出，详见论文《Attention Is All You Need》[107]。Transformer的计算时间与上下文窗口的大小成二次方关系。Jürgen Schmidhuber的快速权重控制器（1992）[108]是线性增长的，后来证明其等价于未经归一化的线性Transformer[109][110][10]。Transformer已逐渐成为自然语言处理的首选模型[111]。许多现代大型语言模型，如ChatGPT、GPT-4和BERT，都采用了这一架构。
\subsection{模型}
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/c118330263ec8756.png}
\caption{神经元和有髓轴突，信号从树突的输入流向轴突末端的输出} \label{fig_RGSJ_2}
\end{figure}
人工神经网络（ANN）最初是试图利用人脑的结构来执行传统算法难以成功的任务。很快，它们开始重新定位，专注于提高经验结果，放弃了保持忠于生物学原型的尝试。人工神经网络能够学习并建模非线性和复杂的关系。这是通过神经元之间以各种模式连接实现的，允许某些神经元的输出成为其他神经元的输入。网络形成了一个有向加权图[112]。

人工神经网络由模拟神经元组成。每个神经元通过类似生物轴突-突触-树突连接的链接与其他节点相连。所有通过链接连接的节点接收一些数据，并利用这些数据执行特定的操作和任务。每个链接都有一个权重，决定了一个节点对另一个节点的影响力[113]，通过调整权重来选择神经元之间的信号传递。
\subsubsection{人工神经元}  
人工神经网络（ANNs）由人工神经元组成，概念上源自生物神经元。每个人工神经元有输入并生成一个输出，这个输出可以传递给多个其他神经元。[114] 输入可以是外部数据样本的特征值，例如图像或文档，也可以是其他神经元的输出。神经网络的最终输出神经元的输出完成任务，例如识别图像中的物体。[citation needed]

为了找到神经元的输出，我们将所有输入的加权和相加，加权由从输入到神经元的连接的权重决定。我们还会在这个和上加上一个偏置项。[115] 这个加权和有时称为激活值。然后，这个加权和通过一个（通常是非线性的）激活函数来生成输出。初始输入是外部数据，例如图像和文档。最终的输出完成任务，例如识别图像中的物体。[116]”