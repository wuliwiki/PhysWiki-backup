% 人工神经网络（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/9fddb6b4ea5a9fd3.png}
\caption{人工神经网络是一个互相连接的节点群，灵感来源于大脑中神经元的简化模型。在这里，每个圆形节点代表一个人工神经元，箭头代表从一个人工神经元的输出到另一个人工神经元输入的连接。} \label{fig_RGSJ_1}
\end{figure}
在机器学习中，神经网络（也称为人工神经网络或神经网，缩写为ANN或NN）是一种受到动物大脑生物神经网络结构和功能启发的模型。[1][2]

一个人工神经网络由连接的单元或节点组成，这些节点被称为人工神经元，粗略地模拟大脑中的神经元。这些神经元通过边（连接）相互连接，模拟大脑中的突触。每个人工神经元接收来自连接神经元的信号，然后处理这些信号并将结果传送给其他连接的神经元。这个“信号”是一个实数，每个神经元的输出通过某个非线性函数计算，该函数作用于输入的和，这个过程被称为激活函数。每个连接的信号强度由一个权重决定，权重会在学习过程中调整。

通常，神经元会被聚合成层。不同的层可能对其输入执行不同的变换。信号从第一层（输入层）传输到最后一层（输出层），可能会经过多个中间层（隐藏层）。如果一个网络至少有两个隐藏层，通常称其为深度神经网络。[3]

人工神经网络被用于各种任务，包括预测建模、自适应控制和解决人工智能中的问题。它们能够从经验中学习，并能够从复杂且看似不相关的信息集中推导结论。
\subsection{训练}
神经网络通常通过经验风险最小化进行训练。这种方法基于优化网络参数，以最小化预测输出与给定数据集中的实际目标值之间的差异或经验风险的理念。[4] 基于梯度的方法，如反向传播，通常用于估计网络的参数。[4] 在训练阶段，人工神经网络通过标记的训练数据进行学习，通过迭代更新参数以最小化定义的损失函数。[5] 这种方法使得网络能够对未见过的数据进行泛化。
\subsection{历史}  
\subsubsection{早期工作}  
今天的深度神经网络基于200多年前统计学的早期工作。最简单的前馈神经网络（FNN）是一个线性网络，它由一层输出节点组成，节点使用线性激活函数；输入通过一系列权重直接馈送到输出。在每个节点上，输入和权重的乘积之和会被计算出来。通过对这些计算的输出与给定目标值之间的均方误差进行最小化，调整权重。这种技术已经有两个多世纪的历史，被称为最小二乘法或线性回归。它由勒让德（1805年）和高斯（1795年）用于预测行星运动，通过找到一组点的最佳线性拟合。[7][8][9][10][11]  

历史上，像冯·诺依曼模型这样的数字计算机通过执行显式指令并通过多个处理器访问内存来操作。另一方面，一些神经网络起源于试图通过联结主义框架模拟生物系统中的信息处理。与冯·诺依曼模型不同，联结主义计算不将内存和处理分开。  

沃伦·麦卡洛克和沃尔特·皮茨（1943年）考虑了一个非学习型的神经网络计算模型。[13] 这个模型为神经网络研究分裂成两种不同的方向奠定了基础。一种方向专注于生物过程，而另一种方向则专注于神经网络在人工智能中的应用。

在20世纪40年代末，D.O. Hebb[14] 提出了一个基于神经可塑性机制的学习假设，这个假设后来被称为赫布学习（Hebbian learning）。它被用于许多早期的神经网络中，例如Rosenblatt的感知器和霍普菲尔德网络。Farley和Clark[15]（1954年）使用计算机模拟了一个赫布网络。其他神经网络计算机器由Rochester、Holland、Habit和Duda（1956年）创建。[16]  

1958年，心理学家Frank Rosenblatt描述了感知器，这是一种最早实现的人工神经网络之一，[17][18][19][20] 由美国海军研究办公室资助。[21] R.D. Joseph（1960年）[22] 提到Farley和Clark（1956年）开发的早期感知器类设备：[10] "麻省理工学院林肯实验室的Farley和Clark实际上在感知器类设备的开发上先于Rosenblatt。" 然而，他们“放弃了这个课题。”感知器引发了公众对人工神经网络研究的热情，促使美国政府大幅增加资金。这为计算机科学家对感知器能够模拟人类智能的乐观预期提供了支持，进一步推动了“人工智能的黄金时代”。[23]  

最初的感知器没有自适应的隐藏单元。然而，Joseph（1960年）[22] 也讨论了具有自适应隐藏层的多层感知器。Rosenblatt（1962年）[24]: 第16节 引用并采纳了这些想法，同时也给出了H.D. Block和B.W. Knight的工作。然而，这些早期的努力并未导致隐藏单元的有效学习算法，也就是深度学习的实现未能成功。
\subsubsection{1960年代和1970年代的深度学习突破}
在1960年代和1970年代，人工神经网络（ANNs）进行了基础研究。第一个有效的深度学习算法是数据处理组方法（Group Method of Data Handling），这是一个用于训练任意深度神经网络的方法，由Alexey Ivakhnenko和Lapa于苏联（1965年）提出。他们将其视为一种多项式回归方法，[25] 或者说是Rosenblatt感知器的推广。[26] 1971年的一篇论文描述了一个由这种方法训练的八层深度网络，[27] 该方法基于通过回归分析逐层训练的方式。通过使用单独的验证集修剪冗余的隐藏单元。由于节点的激活函数是Kolmogorov-Gabor多项式，这些也成为了第一个具有乘法单元或“门”的深度网络。[10]

第一个通过随机梯度下降（SGD）训练的深度学习多层感知器（MLP）由Shun'ichi Amari于1967年发布。[29] 在Amari的学生Saito进行的计算机实验中，一个具有五层的多层感知器（MLP）通过修改两层的方式学习了内部表示，用于对非线性可分模式类别进行分类。[10] 随着硬件和超参数调优的发展，端到端的随机梯度下降目前已成为主流的训练技术。

1969年，Kunihiko Fukushima引入了ReLU（修正线性单元）激活函数。[10][30][31] 修正器成为了深度学习中最流行的激活函数。[32]

尽管如此，在美国的研究在Minsky和Papert（1969年）的工作之后停滞不前，[33] 他们强调基础感知器无法处理异或（exclusive-or）电路。这个洞察对Ivakhnenko（1965年）和Amari（1967年）的深度网络并不适用。

1976年，迁移学习在神经网络学习中被引入。[34][35]

深度学习架构用于卷积神经网络（CNNs），包括卷积层、降采样层和权重复制，始于Kunihiko Fukushima于1979年引入的Neocognitron，尽管该网络并未通过反向传播进行训练。[36][37][38]
\subsubsection{反向传播}
反向传播是一种有效的链式法则应用，由戈特弗里德·威廉·莱布尼茨（Gottfried Wilhelm Leibniz）于1673年提出[39]，用于可微节点的网络。术语“反向传播误差”最早是由Rosenblatt在1962年提出的，[24] 但当时他并不知道如何实现这一过程，尽管亨利·J·凯利（Henry J. Kelley）在1960年在控制理论的背景下已经有了反向传播的连续先驱[40]。1970年，塞波·林奈马（Seppo Linnainmaa）在他的硕士论文中发表了现代形式的反向传播（1970年）[41][42][10]。G.M. 奥斯特罗夫斯基（G.M. Ostrovski）等人在1971年重新发表了这一工作[43][44]。保罗·韦尔博斯（Paul Werbos）在1982年将反向传播应用于神经网络[45][46]（他的1974年博士论文，1994年再版的书籍[47]中并未描述该算法[44]）。1986年，大卫·E·鲁梅哈特（David E. Rumelhart）等人普及了反向传播，但没有引用原始的工作[48]。
\subsubsection{卷积神经网络}
1979年，福岛邦彦（Kunihiko Fukushima）提出的卷积神经网络（CNN）架构[36]，同时引入了最大池化（max pooling）[49]，这一程序成为CNN中常用的下采样方法。卷积神经网络（CNN）已成为计算机视觉领域的重要工具。

时延神经网络（TDNN）由亚历克斯·韦博尔（Alex Waibel）于1987年提出，旨在将CNN应用于音素识别。它使用了卷积、权重共享和反向传播技术[50][51]。1988年，张伟（Wei Zhang）将一个经过反向传播训练的CNN应用于字母识别[52]。1989年，扬·勒昆（Yann LeCun）等人创建了一个名为LeNet的CNN，用于识别邮寄物品上的手写邮政编码。训练过程耗时3天[53]。1990年，张伟将CNN实现于光学计算硬件上[54]。1991年，CNN被应用于医学影像中的物体分割[55]以及乳腺癌的乳腺X光检测[56]。LeNet-5（1998），由扬·勒昆等人提出的一个7层CNN，用于对数字进行分类，被几家银行应用于识别支票上手写的数字，数字图像为32×32像素[57]。

自1988年起[58][59]，神经网络的使用在蛋白质结构预测领域带来了变革，尤其是在第一个级联网络通过多重序列比对生成的轮廓（矩阵）进行训练时[60]。
\subsubsection{循环神经网络}
RNN（循环神经网络）的一个起源是统计力学。1972年，天野俊一（Shun'ichi Amari）提出通过Hebbian学习规则修改Ising模型的权重，作为联想记忆的模型，并加入了学习的成分[61]。这一概念由约翰·霍普菲尔德（John Hopfield）于1982年推广为霍普菲尔德网络[62]。RNN的另一个起源是神经科学。术语“recurrent”（循环）用于描述解剖学中的环路结构。1901年，卡哈尔（Cajal）在小脑皮层观察到“循环半圆形”结构[63]。赫布（Hebb）则将“回响电路”作为短期记忆的解释[64]。麦卡洛克和皮茨（McCulloch and Pitts，1943）在论文中考虑了包含循环的神经网络，并指出此类网络的当前活动可以受到远古历史中活动的影响[12]。

1982年，提出了一种名为**Crossbar Adaptive Array**的循环神经网络（而非多层感知器结构），其使用了从输出到监督（教师）输入的直接递归连接。除了计算行动（决策），它还计算了结果情境的内部状态评估（情感）。通过消除外部监督，该网络引入了神经网络中的自我学习方法。

在1980年代初期的认知心理学期刊《American Psychologist》中，开展了一场关于认知与情感之间关系的辩论。1980年，扎琼茨（Zajonc）表示情感是首先计算的，并且独立于认知，而拉扎鲁斯（Lazarus）则在1982年指出，认知是首先计算的，并且与情感不可分离[67][68]。1982年，Crossbar Adaptive Array提出了一种神经网络模型来说明认知-情感关系[65][69]。这是人工智能系统——一种循环神经网络——在认知心理学领域所贡献的一个例子。

两项早期有影响力的工作是乔丹网络（Jordan Network，1986）和埃尔曼网络（Elman Network，1990），它们应用RNN研究认知心理学。

在1980年代，反向传播算法在深层RNN上表现不佳。为了克服这一问题，1991年，Jürgen Schmidhuber提出了“神经序列分块器”（neural sequence chunker）或“神经历史压缩器”（neural history compressor）[70][71]，该方法引入了自我监督预训练（ChatGPT中的“P”）和神经知识蒸馏的重要概念[10]。1993年，一个神经历史压缩系统解决了一个需要超过1000层递归展开的“非常深的学习”任务[72]。

1991年，Sepp Hochreiter的学位论文[73]识别并分析了梯度消失问题[73][74]，并提出了递归残差连接来解决该问题。他与Schmidhuber一起提出了长短期记忆（LSTM），在多个应用领域创造了准确度记录[75][76]。但这还不是现代版本的LSTM，现代LSTM需要遗忘门（forget gate），该门在1999年被引入[77]。它成为了RNN架构的默认选择。

在1985到1995年间，受到统计力学启发，Terry Sejnowski、Peter Dayan、Geoffrey Hinton等人开发了多个架构和方法，包括Boltzmann机[78]、限制玻尔兹曼机[79]、赫尔姆霍兹机[80]和唤醒-睡眠算法[81]。这些方法设计用于深度生成模型的无监督学习。
\subsubsection{深度学习}
在2009到2012年间，人工神经网络（ANN）开始在图像识别竞赛中获奖，并在各种任务上接近人类水平的表现，最初是在模式识别和手写识别方面[82][83]。2011年，Dan Ciresan、Ueli Meier、Jonathan Masci、Luca Maria Gambardella和Jürgen Schmidhuber团队提出的CNN模型DanNet[84][85]首次在视觉模式识别竞赛中取得超人类表现，超越传统方法三倍[38]。随后它继续赢得了更多竞赛[86][87]。他们还展示了在GPU上使用最大池化CNN显著提高了性能[88]。

2012年10月，Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton提出的AlexNet[89]在ImageNet大型竞赛中以显著的优势战胜了浅层机器学习方法。随后的增量改进包括Karen Simonyan和Andrew Zisserman提出的VGG-16网络[90]以及Google的Inceptionv3[91]。

2012年，吴恩达（Ng）和Dean创造了一个网络，仅通过观看无标签图像，便学习识别更高层次的概念，例如猫[92]。无监督预训练和来自GPU和分布式计算的计算能力提升，使得能够使用更大的网络，特别是在图像和视觉识别问题中，这被称为“深度学习”[5]。

2013年，径向基函数和小波网络被引入。这些网络展示了最佳逼近性质，并已应用于非线性系统识别和分类问题[93]。

生成对抗网络（GAN）（Ian Goodfellow等人，2014）[94]在2014到2018年期间成为生成建模领域的技术前沿。GAN原理最早由Jürgen Schmidhuber于1991年提出，他称之为“人工好奇心”：两个神经网络通过零和博弈的形式相互竞争，其中一个网络的获益是另一个网络的损失[95][96]。第一个网络是生成模型，它建模输出模式的概率分布。第二个网络通过梯度下降学习预测环境对这些模式的反应。Nvidia的StyleGAN（2018）[97]基于Tero Karras等人提出的Progressive GAN[98]，成功实现了优质图像生成。这里，GAN生成器以金字塔的形式从小到大逐步增长。GAN的图像生成取得了广泛成功，并引发了关于深度伪造（deepfakes）的讨论[99]。自此以来，扩散模型（2015）[100]在生成建模中超越了GAN，出现了DALL·E 2（2022）和Stable Diffusion（2022）等系统。

2014年，技术前沿是训练具有20到30层的“非常深的神经网络”[101]。堆叠过多的层导致训练准确度急剧下降[102]，即“退化”问题[103]。2015年，提出了两种训练非常深网络的技术：高速公路网络（highway network）在2015年5月发布[104]，残差神经网络（ResNet）在2015年12月发布[105][106]。ResNet类似于开门的高速公路网络。

在2010年代，seq2seq模型被开发出来，并加入了注意力机制。2017年，这导致了现代Transformer架构的提出，详见论文《Attention Is All You Need》[107]。Transformer的计算时间与上下文窗口的大小成二次方关系。Jürgen Schmidhuber的快速权重控制器（1992）[108]是线性增长的，后来证明其等价于未经归一化的线性Transformer[109][110][10]。Transformer已逐渐成为自然语言处理的首选模型[111]。许多现代大型语言模型，如ChatGPT、GPT-4和BERT，都采用了这一架构。
\subsection{模型}
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/c118330263ec8756.png}
\caption{神经元和有髓轴突，信号从树突的输入流向轴突末端的输出} \label{fig_RGSJ_2}
\end{figure}
人工神经网络（ANN）最初是试图利用人脑的结构来执行传统算法难以成功的任务。很快，它们开始重新定位，专注于提高经验结果，放弃了保持忠于生物学原型的尝试。人工神经网络能够学习并建模非线性和复杂的关系。这是通过神经元之间以各种模式连接实现的，允许某些神经元的输出成为其他神经元的输入。网络形成了一个有向加权图[112]。

人工神经网络由模拟神经元组成。每个神经元通过类似生物轴突-突触-树突连接的链接与其他节点相连。所有通过链接连接的节点接收一些数据，并利用这些数据执行特定的操作和任务。每个链接都有一个权重，决定了一个节点对另一个节点的影响力[113]，通过调整权重来选择神经元之间的信号传递。
\subsubsection{人工神经元}  
人工神经网络（ANNs）由人工神经元组成，概念上源自生物神经元。每个人工神经元有输入并生成一个输出，这个输出可以传递给多个其他神经元。[114] 输入可以是外部数据样本的特征值，例如图像或文档，也可以是其他神经元的输出。神经网络的最终输出神经元的输出完成任务，例如识别图像中的物体。[citation needed]

为了找到神经元的输出，我们将所有输入的加权和相加，加权由从输入到神经元的连接的权重决定。我们还会在这个和上加上一个偏置项。[115] 这个加权和有时称为激活值。然后，这个加权和通过一个（通常是非线性的）激活函数来生成输出。初始输入是外部数据，例如图像和文档。最终的输出完成任务，例如识别图像中的物体。[116]
\subsubsection{组织结构}  
神经元通常被组织成多个层次，特别是在深度学习中。一个层次的神经元只与紧接其前后层的神经元相连接。接收外部数据的层是输入层。产生最终结果的层是输出层。它们之间可能有零个或多个隐藏层。也有使用单层和无层网络的情况。在两层之间，可能有多种连接模式。它们可以是‘全连接’的，即一个层的每个神经元都与下一个层的每个神经元相连。也可以是池化层，其中一个层中的一组神经元连接到下一个层中的一个神经元，从而减少该层中神经元的数量。[117] 只有这种连接的神经元形成一个有向无环图（DAG），并且被称为前馈网络。[118] 另一种选择是，允许层内或前一层的神经元之间的连接的网络，称为递归网络。[119]
\subsubsection{超参数}   
超参数是一个常数参数，其值在学习过程开始之前就已设定。参数的值是通过学习过程得到的。超参数的例子包括学习率、隐藏层的数量和批量大小。[citation needed] 一些超参数的值可能依赖于其他超参数的值。例如，某些层的大小可能依赖于整体层数。
\subsubsection{学习}
学习是通过考虑样本观察结果，使网络更好地处理任务的适应过程。学习涉及调整网络的权重（和可选的阈值），以提高结果的准确性。这是通过最小化观察到的错误来完成的。当额外观察结果无法有效减少错误率时，学习就完成了。即使在学习后，错误率通常也不会达到 0。如果学习后错误率过高，通常需要重新设计网络。实际操作中，通过定义一个在学习过程中定期评估的代价函数来完成这一过程。只要代价函数的输出继续下降，学习就会继续进行。代价通常定义为一个只能近似计算的统计量。输出实际上是数字，因此当错误较低时，输出（几乎可以确定是猫）与正确答案（猫）之间的差异很小。学习的目标是减少所有观察结果之间差异的总和。大多数学习模型可以看作是优化理论和统计估计的直接应用。[112][120]

\textbf{学习率}

学习率定义了模型在每次观察中调整错误时采取的修正步骤的大小。[121] 高学习率可以缩短训练时间，但会导致最终精度较低；而低学习率则需要更长时间，但可能带来更高的精度。优化方法如Quickprop主要旨在加速错误最小化，而其他改进则主要致力于提高可靠性。为了避免网络内的振荡（例如，连接权重交替变化），并改善收敛速度，改进的方法采用自适应学习率，根据需要调整学习率的增减。[122] 动量的概念使得梯度和之前变化之间的平衡得以加权，从而权重调整在某种程度上依赖于先前的变化。接近0的动量强调梯度，而接近1的动量则强调最后的变化。

\textbf{代价函数}

虽然可以随意定义代价函数，但通常选择是根据函数的理想属性（例如凸性）或因为它来自于模型本身（例如在概率模型中，模型的后验概率可以用作反向代价）来决定的。

\textbf{反向传播}

反向传播是一种方法，用于调整连接权重，以弥补在学习过程中发现的每个错误。错误量会在各个连接之间有效地分配。技术上，反向传播计算的是代价函数相对于给定状态的权重的梯度（导数）。权重更新可以通过随机梯度下降或其他方法来完成，例如极限学习机，[123] "no-prop" 网络，[124] 无回溯训练，[125] "无权重" 网络，[126][127] 和非连接主义神经网络。
\subsection{学习范式}
机器学习通常分为三种主要的学习范式：监督学习、无监督学习和强化学习。每种范式对应一种特定的学习任务。

\textbf{监督学习}  

监督学习使用一组成对的输入和期望输出。学习任务是为每个输入产生期望的输出。在这种情况下，代价函数与消除错误推断有关。常用的代价函数是均方误差，它试图最小化网络输出与期望输出之间的平均平方误差。适合监督学习的任务包括模式识别（也称为分类）和回归（也称为函数逼近）。监督学习还适用于序列数据（例如，手写、语音和手势识别）。可以将其视为带有“教师”的学习形式，教师通过提供对目前得到的解决方案质量的持续反馈来指导学习。

\textbf{无监督学习}  

在无监督学习中，输入数据与代价函数一起提供，代价函数是数据 \( x \) 和网络输出的某个函数。代价函数依赖于任务（模型领域）以及任何先验假设（模型的隐式属性、参数和观察变量）。举个简单的例子，考虑模型 \( f(x) = a \)，其中 \( a \) 是常数，代价为 \( C = E[(x - f(x))^2] \)。最小化这个代价函数会得到一个值 \( a \)，它等于数据的均值。代价函数可以更加复杂，其形式取决于应用。例如，在压缩中，代价函数可能与输入 \( x \) 和输出 \( f(x) \) 之间的互信息有关；而在统计建模中，它可能与给定数据的模型的后验概率有关（注意，在这两个例子中，这些量应当是最大化而非最小化）。无监督学习范式中的任务通常是估计问题；其应用包括聚类、统计分布估计、压缩和过滤。

\textbf{强化学习}  

在一些应用中，如玩视频游戏，行动者（agent）执行一系列动作，每执行一个动作后，从环境中接收一个通常无法预测的反馈。目标是赢得游戏，即产生最积极（成本最低）的响应。在强化学习中，目标是通过加权网络（制定策略），执行能够最小化长期（预期累计）成本的动作。在每个时间点，代理执行一个动作，环境根据一些（通常是未知的）规则生成一个观察值和即时成本。规则和长期成本通常只能被估算。在任何时刻，代理需要决定是探索新的动作以发现其成本，还是利用之前的学习结果来更快地进行决策。

形式上，环境被建模为一个马尔可夫决策过程（MDP），其中有状态 \( s_1, \dots, s_n \in S \) 和动作 \( a_1, \dots, a_m \in A \)。由于状态转移是未知的，因此使用概率分布来代替：即时成本分布 \( P(c_t | s_t) \)、观察分布 \( P(x_t | s_t) \) 和转移分布 \( P(s_{t+1} | s_t, a_t) \)，而策略被定义为给定观察结果下的条件动作分布。两者结合起来，定义了一个马尔可夫链（MC）。目标是发现成本最低的马尔可夫链。

在这些应用中，人工神经网络（ANNs）作为学习组件。[132][133] 动态规划与ANNs结合（形成神经动态规划，Neurodynamic Programming）[134] 已被应用于解决如车辆调度[135]、视频游戏、自然资源管理[136][137]和医学[138]等问题，因为ANNs能够在减少离散化网格密度的情况下，仍然有效减轻准确性损失，这对于数值近似控制问题的解决尤为重要。强化学习范式下的任务通常是控制问题、游戏和其他顺序决策任务。

\textbf{自学习}  

神经网络中的自学习概念在1982年被引入，同时提出了一种能够自学习的神经网络，称为交叉适应阵列（Crossbar Adaptive Array, CAA）。[139] 该系统仅有一个输入——情况 \( s \)，和一个输出——行为（或动作）\( a \)。它既没有来自外部的建议输入，也没有来自环境的外部强化输入。CAA通过交叉方式计算关于动作的决策和对于遇到情况的情感（感受）。该系统由认知与情感之间的互动驱动。[140] 给定记忆矩阵 \( W = ||w(a, s)|| \)，每次迭代中的交叉自学习算法执行以下计算：

\\在情况 \( s \) 下执行动作 \( a \)；\\
接受结果情况 \( s' \)；\\
计算在结果情况中的情感 \( v(s') \)；\\
更新交叉适应记忆：\( w'(a, s) = w(a, s) + v(s') \)。\\

反向传播的值（次级强化）是对结果情况的情感。CAA存在于两个环境中，一个是行为环境，系统在其中执行动作；另一个是遗传环境，CAA在其中初次且唯一一次接收关于将要遇到的情况的初步情感。接收到来自遗传环境的基因组向量（物种向量）后，CAA将在行为环境中学习目标寻求行为，这个环境包含了既有可取的情况也有不可取的情况。[141]

\textbf{神经进化}  
 
神经进化可以通过进化计算来创建神经网络的拓扑结构和权重。它与复杂的梯度下降方法具有竞争力。[142][143] 神经进化的一个优势是，它可能不容易陷入“死胡同”。[144]
\subsubsection{随机神经网络}  
源自Sherrington-Kirkpatrick模型的随机神经网络是一种通过引入随机变化到网络中的人工神经网络，可以通过给网络的人工神经元提供随机传输函数[需要引用]，或通过赋予它们随机权重来实现。这使得它们成为优化问题的有用工具，因为随机波动帮助网络摆脱局部最小值。[145] 使用贝叶斯方法训练的随机神经网络被称为贝叶斯神经网络。[146]
\subsubsection{其他}  
在贝叶斯框架中，选择一个分布来对允许的模型集合进行建模，以最小化成本。进化方法[147]、基因表达编程[148]、模拟退火[149]、期望最大化、非参数方法和粒子群优化[150]是其他学习算法。收敛递归是一种用于小脑模型发音控制器（CMAC）神经网络的学习算法。[151][152]

\textbf{Modes}

有两种学习模式：随机学习和批量学习。在随机学习中，每个输入都会导致一次权重调整。在批量学习中，权重是基于一批输入进行调整的，错误会在批量中累积。随机学习通过使用从一个数据点计算出的局部梯度引入“噪声”，这可以减少网络陷入局部最小值的概率。然而，批量学习通常会更快且更稳定地向局部最小值下降，因为每次更新都朝着批量的平均误差方向进行。一种常见的折衷方法是使用“迷你批次”，即从整个数据集中随机选择的包含样本的小批次。
\subsection{类型}   
人工神经网络（ANNs）已经发展成一个广泛的技术家族，推动了多个领域的技术进步。最简单的类型包括一个或多个静态组件，如单元数量、层数、单元权重和拓扑结构。动态类型允许通过学习使其中一个或多个组件发生变化。后者要复杂得多，但可以缩短学习周期并产生更好的结果。一些类型允许或要求学习由操作员“监督”，而另一些则独立运作。有些类型完全在硬件上运行，而其他类型则纯软件实现，运行在通用计算机上。

一些主要的突破包括：
\begin{itemize}
\item 卷积神经网络（CNN），它在处理视觉和其他二维数据方面特别成功；[153][154] 其中长短期记忆（LSTM）避免了梯度消失问题[155]，能够处理混合低频和高频成分的信号，帮助实现大词汇量的语音识别、[156][157] 文本到语音合成、[158][159][160] 和照片级真实感的虚拟人头语音合成；[161]  
\item 竞争性网络，如生成对抗网络（GAN），其中多个网络（具有不同结构）在任务中相互竞争，比如赢得比赛[162] 或者欺骗对方输入的真实性。[94]
\end{itemize}
\subsection{网络设计}  
使用人工神经网络（ANNs）需要了解其特点。

\begin{itemize}
\item 模型选择：这取决于数据表示和应用。模型参数包括网络层的数量、类型和连接方式，以及每层的大小和连接类型（全连接、池化等）。过于复杂的模型学习速度较慢。
\item 学习算法：不同的学习算法之间存在许多权衡。几乎任何算法只要使用正确的超参数[163]，都能在特定数据集上表现良好。然而，选择并调优一个算法以用于未见数据的训练，通常需要大量的实验。
\item 鲁棒性：如果模型、成本函数和学习算法选择得当，得到的人工神经网络（ANN）可以变得非常鲁棒
\end{itemize}。

神经架构搜索（NAS）：NAS利用机器学习自动化ANN设计。各种NAS方法已经设计出与人工设计系统相媲美的网络。基本的搜索算法是提出一个候选模型，评估其在数据集上的表现，并利用结果作为反馈来指导NAS网络的学习。[164] 可用的系统包括AutoML和AutoKeras。[165] scikit-learn库提供了一些函数，帮助从零开始构建深度网络。然后可以使用TensorFlow或Keras来实现深度网络。

超参数也需要在设计过程中定义（它们不是通过学习获得的），它们决定了每层有多少个神经元、学习率、步长、步伐、深度、感受野和填充（对于CNN）等事项。[166]

下面的Python代码片段概述了训练函数，它使用训练数据集、隐藏层单元的数量、学习率和迭代次数作为参数：
\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/996b23cfb9154b7e.png}
\caption{} \label{fig_RGSJ_3}
\end{figure}
\subsection{应用}  
由于人工神经网络能够重现和建模非线性过程，它们在许多学科中找到了应用。包括：
\begin{itemize}
\item 函数逼近[167] 或回归分析[168]（包括时间序列预测、适应度逼近[169] 和建模）
\item 数据处理[170]（包括滤波、聚类、盲源分离[171] 和压缩）
\item 非线性系统识别[93] 和控制（包括车辆控制、轨迹预测[172]、自适应控制、过程控制和自然资源管理）
\item 模式识别（包括雷达系统、面部识别、信号分类[173]、新奇检测、3D重建[174]、物体识别和序列决策[175]）
\item 序列识别（包括手势、语音以及手写和打印文本识别[176]）
\item 传感器数据分析[177]（包括图像分析）
\item 机器人学（包括操作机械臂和假肢的引导）
\item 数据挖掘（包括数据库中的知识发现）
\item 金融[178]（例如，用于特定金融长期预测的事前模型和人工金融市场）
\item 量子化学[179]
\item 通用游戏对战[180]
\item 生成式人工智能[181]
\item 数据可视化
\item 机器翻译
\item 社交网络过滤[182]
\item 电子邮件垃圾邮件过滤
\item 医学诊断[183]
\end{itemize}
人工神经网络（ANNs）已被用于诊断多种类型的癌症[184][185]，并通过仅使用细胞形状信息区分高度侵袭性的癌细胞系和低侵袭性的细胞系[186][187]。

人工神经网络已被用于加速自然灾害对基础设施的可靠性分析[188][189]，并预测地基沉降[190]。它还可用于通过模拟降水-径流来缓解洪水[191]。ANNs 也已被用于在地球科学中构建黑箱模型，如水文学[192][193]、海洋建模和沿海工程[194][195]，以及地貌学[196]。ANNs 在网络安全中得到了应用，目标是区分合法活动和恶意活动。例如，机器学习已被用于分类 Android 恶意软件[197]，识别属于威胁行为者的域名，以及检测存在安全风险的 URL[198]。目前正在研究为渗透测试、检测僵尸网络[199]、信用卡欺诈[200]和网络入侵设计的 ANN 系统。

人工神经网络已被提出作为解决物理学中偏微分方程的工具[201][202][203]，并模拟多体开放量子系统的性质[204][205][206][207]。在大脑研究中，ANNs 研究了单个神经元的短期行为[208]，神经回路的动态是由单个神经元之间的相互作用产生的，以及行为如何从表示完整子系统的抽象神经模块中产生。研究还考虑了神经系统的长期和短期可塑性以及它们与学习和记忆的关系，从单个神经元到系统层面。

使用人工神经网络进行物体识别，可以从图片中创建用户兴趣的个人资料[209]。

除了传统的应用领域，人工神经网络在跨学科研究中也越来越受到利用，例如材料科学。例如，图神经网络（GNNs）已经证明其在新稳定材料发现中的能力，通过高效预测晶体的总能量来扩展深度学习的应用。这一应用突显了ANNs在解决复杂问题方面的适应性和潜力，超越了预测建模和人工智能的领域，为科学发现和创新开辟了新路径[210]。
\subsection{理论属性}
\subsubsection{计算能力}  
多层感知机（Multilayer Perceptron, MLP）是一个通用的函数逼近器，这一点已通过普遍逼近定理得到证明。然而，这一证明并没有对所需的神经元数量、网络拓扑、权重以及学习参数提供构造性的指导。

具有有理数权重（而非全精度实数权重）的特定递归架构具有通用图灵机的能力[211]，只需有限数量的神经元和标准的线性连接。此外，使用无理数作为权重值会使得机器具有超图灵能力[212][213]（未验证）。
\subsubsection{容量} 
一个模型的“容量”属性对应于其对任何给定函数建模的能力。它与网络中可以存储的信息量以及复杂性的概念相关。社区已知有两种容量的概念：信息容量和VC维度（Vapnik-Chervonenkis Dimension）。感知机的信息容量在Sir David MacKay的书中得到了广泛讨论[214]，该书总结了Thomas Cover的工作[215]。标准神经元（非卷积神经元）网络的容量可以通过四条规则推导出来[216]，这些规则源于将神经元理解为电气元件的理论。信息容量捕捉了给定任何输入数据时，网络能够建模的函数。第二个概念是VC维度。VC维度使用测度理论的原理，找出在最佳条件下的最大容量，即给定特定形式的输入数据。如在[214]中所述，任意输入的VC维度是感知机信息容量的一半。任意点的VC维度有时被称为“记忆容量”[217]。
\subsubsection{收敛性}
模型可能无法始终收敛到单一解，首先是因为存在局部最小值，这取决于代价函数和模型。其次，所使用的优化方法可能无法保证在距离任何局部最小值较远时就收敛。第三，对于足够大的数据或参数，一些方法变得不切实际。

另一个值得提到的问题是，训练过程中可能会经过一些鞍点，从而导致收敛方向错误。

某些类型的ANN架构的收敛行为比其他类型更为清楚。当网络的宽度趋近于无穷大时，ANN在训练过程中可以通过其一阶泰勒展开式很好地描述，因此继承了仿射模型的收敛行为[218][219]。另一个例子是当参数较小时，观察到ANN通常从低频到高频拟合目标函数。这种行为被称为神经网络的频谱偏差或频率原理[220][221][222][223]。这一现象与一些著名的迭代数值方法（如雅可比法）行为相反。深层神经网络通常对低频函数有更强的偏好[224]。
\subsubsection{泛化与统计学}
目标是创建一个能够很好地泛化到未见过的样本的系统的应用，面临着过度训练的可能性。这种问题出现在复杂或过度指定的系统中，当网络的容量远远超过所需的自由参数时，就会出现过度训练。解决过度训练的有两种方法。第一种方法是使用交叉验证和类似技术检查是否存在过度训练，并选择超参数以最小化泛化误差。

第二种方法是使用某种形式的正则化。这个概念出现在概率（贝叶斯）框架中，在这种框架下，正则化可以通过选择对简单模型的更大先验概率来执行；它也出现在统计学习理论中，在该理论中，目标是最小化两个量：‘经验风险’和‘结构风险’，这大致对应于训练集上的误差以及由于过拟合导致在未见过的数据上的预测误差。
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/40326eed14e03bb6.png}
\caption{神经网络的置信度分析} \label{fig_RGSJ_4}
\end{figure}
使用均方误差（MSE）成本函数的监督神经网络可以使用正式的统计方法来确定训练模型的置信度。验证集上的MSE可以作为方差的估计值。然后，可以使用该值来计算网络输出的置信区间，假设输出符合正态分布。只要输出概率分布保持不变，并且网络没有被修改，这种置信度分析在统计学上是有效的。

通过在神经网络的输出层（或在基于组件的网络中使用软最大化组件）上分配一个软最大化激活函数，这个函数是逻辑函数的广义形式，可以用于分类目标变量，输出值可以解释为后验概率。这在分类任务中非常有用，因为它提供了分类结果的确定性度量。

软最大化激活函数为：
\[
y_i = \frac{e^{x_i}}{\sum_{j=1}^{c} e^{x_j}}~
\]
\subsection{批评}
\subsubsection{训练}
神经网络，尤其是在机器人领域，常受到批评，因为它们需要大量的训练样本才能在现实世界中运行。任何学习机器都需要足够具代表性的示例，以便捕捉到能够使其泛化到新案例的潜在结构。潜在的解决方案包括：通过随机打乱训练示例，使用数值优化算法，在更改网络连接时不会采取过大的步骤，或者使用所谓的小批量训练，将示例分组，和/或为CMAC引入递归最小二乘算法。Dean Pomerleau使用神经网络训练机器人车在多种道路类型上行驶（单车道、多车道、土路等），他的研究大部分致力于从单次训练经历中推断多个训练情景，并保持过去训练的多样性，以避免系统过度训练（例如，如果系统只被呈现连续的右转情景，它不应学会总是右转）。
\subsubsection{理论}
人工神经网络（ANNs）的一个核心论点是，它们体现了处理信息的新型且强大的通用原则。然而，这些原则并没有明确的定义。通常有人声称[需要引用]，这些原则是从网络本身产生的。这使得简单的统计关联（人工神经网络的基本功能）能够被描述为学习或识别。1997年，前《科学美国人》专栏作家亚历山大·杜德尼（Alexander Dewdney）评论道，人工神经网络具有“只取不舍的特性，赋予其一种懒惰的气质，并且对这些计算系统的实际效果缺乏好奇心。没有人类的手（或头脑）干预；解决方案仿佛是魔法般自然而然地出现；似乎没有人学到什么。”[227] 对杜德尼的回应之一是，神经网络已成功地应用于许多复杂多样的任务，从自主飞行的飞机[228]到信用卡欺诈检测，再到精通围棋游戏。

科技作家罗杰·布里奇曼评论道：

“例如，神经网络之所以被批评，不仅因为它们被炒得天花乱坠（有什么不是？），还因为你可以在不了解其工作原理的情况下创建一个成功的网络：那些捕捉其行为的一堆数字很可能会是‘一个不透明、不可读的表格……作为科学资源毫无价值’。”

尽管他强调科学与技术是不同的，杜德尼似乎在这里将神经网络批判为糟糕的科学，而实际上，大多数开发神经网络的人只是试图做出好的工程设计。即使是一个不可读的表格，如果有用的机器能够读取，仍然是非常值得拥有的。[229]

虽然分析人工神经网络所学到的内容确实很困难，但比分析生物神经网络所学到的内容要容易得多。此外，近年来对人工智能可解释性的重视促成了基于注意力机制的可视化方法的发展，用于解释和理解已学到的神经网络。进一步的研究者正在逐渐揭示出一些通用的原则，这些原则使得学习机器能够成功。例如，Bengio和LeCun（2007）撰写了一篇关于局部学习与非局部学习、浅层架构与深层架构的文章。[230]

生物大脑使用浅层和深层电路，如大脑解剖学所报告的那样，展现出各种各样的不变性。Weng[232]认为，大脑的自我连接主要是根据信号统计进行的，因此，序列级联无法捕捉所有主要的统计依赖关系。
\subsubsection{硬件}
大型且高效的神经网络需要相当可观的计算资源。[233] 尽管大脑具有专门的硬件来处理通过神经元图进行信号处理，但即使在冯·诺依曼架构上模拟一个简化的神经元也可能消耗大量的内存和存储。此外，设计者通常需要通过许多连接及其相关的神经元传输信号，这需要巨大的 CPU 功率和时间。[需要引用]

有人认为，神经网络在21世纪的复兴在很大程度上归功于硬件的进步：从1991年到2015年，计算能力，尤其是由 GPGPU（通用图形处理单元）提供的计算能力，已经增加了大约百万倍，使得标准的反向传播算法能够训练比以前深得多的多层网络。[38] 使用加速器，如 FPGA 和 GPU，可以将训练时间从几个月缩短到几天。[233][234]

类脑工程（Neuromorphic engineering）或物理神经网络直接通过构建非冯·诺依曼芯片来解决硬件难题，从而在电路中直接实现神经网络。另一种为神经网络处理优化的芯片被称为张量处理单元（Tensor Processing Unit，TPU）。[235]
\subsubsection{实际反例}
分析人工神经网络（ANN）所学到的内容比分析生物神经网络所学到的内容要容易得多。此外，致力于探索神经网络学习算法的研究人员正在逐渐揭示一些通用原则，这些原则使得学习机器能够成功。例如，局部学习与非局部学习以及浅层架构与深层架构的比较。[236]
\subsubsection{混合方法}
混合模型（结合神经网络和符号方法）的支持者认为，这种混合能够更好地捕捉人类思维的机制。[237][238]
\subsubsection{数据集偏差}
神经网络依赖于其训练数据的质量，因此低质量的数据或具有不平衡代表性的数据可能导致模型学习并延续社会偏见。[239][240] 当神经网络被应用于现实场景时，这些继承的偏见尤为关键，因为训练数据可能因某一特定种族、性别或其他属性的数据稀缺而不平衡。[239] 这种不平衡可能导致模型对代表性不足群体的理解和表现不充分，从而产生歧视性结果，进一步加剧社会不平等，尤其是在面部识别、招聘流程和执法等应用中。[240][241] 例如，2018年，亚马逊不得不放弃一款招聘工具，因为该模型倾向于选择男性而非女性从事软件工程工作，这是因为该领域男性员工比例较高。[241] 该程序会惩罚任何带有“woman”一词或任何女性学院名称的简历。然而，使用合成数据可以帮助减少数据集偏差并增加数据集的代表性。[242]
\subsection{画廊}
\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{./figures/3fed383b8a2c22e0.png}
\caption{} \label{fig_RGSJ_6}
\end{figure}
一个单层前馈人工神经网络。为了清晰起见，箭头从 \( x_2 \) 出发的部分已省略。这个网络有 \( p \) 个输入和 \( q \) 个输出。在该系统中，第 \( q \) 个输出的值 \( y_q \) 计算公式为：
\[
y_q = K \times \left( \sum_i (x_i \times w_{iq}) - b_q \right)~
\]