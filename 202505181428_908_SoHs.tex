% Softmax 函数（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Softmax_function}{相关文章}。

Softmax 函数，也称为 softargmax1: 184  或归一化指数函数2: 198 ，能够将一个长度为 K 的实数向量转换为 K 个可能结果的概率分布。它是逻辑函数在多维空间的推广形式，常用于多项式逻辑回归中。Softmax 函数通常作为神经网络中最后一层的激活函数，用于将网络输出归一化为对各个预测类别的概率分布。
\subsection{定义}
Softmax 函数以一个长度为 $K$ 的实数向量 $\mathbf{z}$ 作为输入，并将其归一化为一个概率分布：该分布由 $K$ 个概率值组成，每个概率值与输入中对应元素的指数成正比。也就是说，在应用 Softmax 之前，向量中的某些分量可能为负，或大于 1，且它们的和不一定为 1；但在应用 Softmax 之后，每个分量都将位于区间 $(0, 1)$ 之内，并且所有分量之和为 1，因此可以将它们解释为概率。此外，输入值越大的分量，对应的概率也越大。

标准（单位）Softmax 函数$\sigma: \mathbb{R}^K \to (0,1)^K$,其中 $K > 1$，它接收一个向量$\mathbf{z} = (z_1, \dotsc, z_K) \in \mathbb{R}^K$,并计算输出向量$\sigma(\mathbf{z}) \in (0,1)^K$的每个分量，定义为：
$$
\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}.~
$$
换句话说，Softmax 对输入向量 $\mathbf{z}$ 中的每个元素 $z_i$ 应用标准指数函数（即 $e^{z_i}$），然后将所有指数值归一化——即每个指数值除以所有指数值的总和。这个归一化操作保证了输出向量 $\sigma(\mathbf{z})$ 所有分量的和为 1，从而可以被解释为概率分布。

“Softmax”一词来源于指数函数对输入向量中最大值的放大作用。例如，对向量 $(1, 2, 8)$ 进行标准 Softmax 运算，其结果大约为
$
(0.001, 0.002, 0.997)，
$$

也就是说，几乎所有的权重都被分配给了最大值 8 所在的位置。
