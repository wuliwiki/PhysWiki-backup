% 交叉熵
% keys 交叉熵 信息论

交叉熵（Cross entropy）是信息论中一种衡量两个数据分布之间差异的度量。
在离散情形下，随机变量$x$有两个概率分布$P$和$Q$，$P$和$Q$的交叉熵定义如下：
\begin{equation}
H(P,Q)=\sum_i++++P(x)lnQ(x)
\end{equation}