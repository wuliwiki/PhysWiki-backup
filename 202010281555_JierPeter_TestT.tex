% TestTensor

\pentry{Matrix\upref{Mat}}

The word "tensor" was first translated in Structural Mechanics, used to describe the properties of stress, therefore translated as “张力”. The term continues in use today, except the translation now becomes “张量”. Today we realize that the stress tensor is only a particular case for a more general mathematical object, tenosr. This object appears everywhere in physics frequently. We will define the concept of tensor from the fundamental sense, which is the contemporary perspective. We will also demonstrate how a tensor is represented by a matrix or a high dimensional matrix. 

This section is a step-by-step guiding textbook, rather than a list of concepts and theorems. To better understand this section, it is recommended that the reader have solid understanding of linear algebra. 

The definition we use in this section is the most fundamental version. No additional structures or constraints are put onto it; also, Einstein's Summation Agreement is not applied yet, so as to be friendly for beginners. For the common concepts like covariant or contravariant tensors, please refer to the subsequent sections. 



\subsection{Introduction}

Students in physics often ask a question: "what is a tensor?" Usually the students are actually asking "why the moment of intertia, the mass, "

A tensor is a multi-linear map. Particularly, a second-order tensor can be interpreted as a map from two vectors to a scalor, or a map from a vector to another vector. The scalor here refers to an element in the field that defines the vector space; in physics, the field is usually the real numbers or the complex numbers. 

Many physical quantities can be interpreted as linear maps. As an example, mass is a second-order tensor, which maps a force vector to an acceleration vector; the moment of inertia is a second-order tensor, which maps an angular velocity vector to an angular momentum vector. Tensors of different orders may behave differently, but they all share one property: the linearity. When you encounter tensors in the future, I suggest you take some time and think "what quantities does this tensor map from and to"; it helps a deeper understanding. 



\subsection{1-linear function, 2-linear function and their representation}

It is known that given 2 vector spaces $V$ and $W$, we can define a linear map from $V$ to $W$. In this case, we have only 1 independent and 1 dependent variables. A multi-linear map, say, a k-linear map, maps a series of vector spaces $V_1, V_2, \cdots, V_k$ to $W$, so that if only the element in one $V_i$ varies, the map varies in the way a linear map does. 

The simplest case is when $W$ is a 1-dimensional space. In this case, the vector space $W$ is also the field (the real numbers). If the image of a map is some set of numbers, then we have a particular term for such a map, \textbf{function}. This is the same function that you may have seen in high school, as the maps involved in high school are mostly from real numbers to real numbers. Now, since we make $W$ the set of real numbers, we just call the map from $V_1, V_2, \cdots, V_k$ to $W$ a \textbf{linear function}. Now, we are going to introduce the concepts of multi-linear maps, tensors and their representations, step by step, starting with linear functions. 

\subsubsection{Representing linear functions with vectors}

\begin{definition}{Linear functions}
Given the n-dimensional vector space $V$ on $\mathbb{R}$, we call $f:V\rightarrow \mathbb{R}$ a \textbf{linear function} from $V$ to $\mathbb{R}$, if and only if $f$ satisfies the linearity: for any vectors $\bvec{v}_1, \bvec{v}_2\in V$ and scalors $a_1, a_2\in\mathbb{R}$, we have: $a_1f(\bvec{v}_1)+a_2f(\bvec{v}_2)=f(a_1\bvec{v}_1+a_2\bvec{v}_2)$．
\end{definition}


\end{definition}

If we think of $\mathbb{R}$ as a 1-dimensional vector space, then $f$ is a linear map from $V$ onto this vector space. Therefore, if we take any base of $V$ and determine what real numbers $f$ maps the base vectors to, then we can calculate $f(\bvec{v})$ for any vector $\bvec{v}\in V$. 

Now suppose a base of $V$ is $\{\bvec{e}_i\}^n_{i=1}$. If the base vector $\bvec{e}_i$ is mapped to $f(\bvec{e}_i)=m_i\in\mathbb{R}$, then for any vector $\bvec{v}=a_1\bvec{e}_1+a_2\bvec{e}_2+\cdots+a_n\bvec{e}_n$, we can calculate by linearity: 

\begin{equation}
\begin{aligned}
f(a_1\bvec{e}_1+a_2\bvec{e}_2+\cdots+a_n\bvec{e}_n)&=f(a_1\bvec{e}_1)+f(a_2\bvec{e}_2)+\cdots+f(a_n\bvec{e}_n)\\&=m_1a_1+m_2a_2+\cdots+m_na_n
\end{aligned}
\end{equation}


$m_1a_1+m_2a_2+\cdots+m_na_n$can be interpreted as the inner product of $\bvec{m}$ and $\bvec{v}$, where$\bvec{m}=m_1\bvec{e}_1+m_2\bvec{e}_2+\cdots+m_n\bvec{e}_n$．

That is, every linear function $f$ corresponds to a vector $\bvec{m}$, so that $f(\bvec{v})=\bvec{m}\cdot\bvec{v}$．The coordinate of the vector $\bvec{m}$, in the base $\{\bvec{e}_i\}_{i=1}^n$, is $(m_1, m_2, \cdots, m_n)^T$. If we define another base, the coordinate usually changes, but the vector is still the same. 

Since a linear function is a map from a vector space to real numbers, we also call it a 1-linear function. It is to distinguish it from other multi-linear functions, like the 2-linear function we are going to focus on now. 

\subsubsection{Representing 2-linear funcions with matices}

Let's stick to the n-dimensional vector space $V$, except now we take 2 copies of $V$ to construct the map $f:V\times V\rightarrow\mathbb{R}$．

\begin{definition}{2-linear function}
We call $f:V\times V\rightarrow\mathbb{R}$ a 2-linear function, if and only if for any fixed vector $\bvec{v}_0$, both $f(\bvec{v}_0, \bvec{v})$ and $f(\bvec{v}, \bvec{v}_0)$ are 1-linear functions for $\bvec{v}$. In particular, we call $f$ a 2-linear function from $(V, V)$ onto $\mathbb{R}$. 
\end{definition}

An explicit expression for a 2-linear function is as follows: 

\begin{equation}\label{TestT_eq2}
\begin{aligned}
f(a_1\bvec{v}_1+a_2\bvec{v}_2, b_1\bvec{u}_1+b_2\bvec{u}_2)&=a_1f(\bvec{v}_1, b_1\bvec{u}_1+b_2\bvec{u}_2)+a_2f(\bvec{v}_2, b_1\bvec{u}_1+b_2\bvec{u}_2)\\&=a_1b_1f(\bvec{v}_1, \bvec{u}_1)+a_2b_1f(\bvec{v}_2, \bvec{u}_1)+a_1b_2f(\bvec{v}_1, \bvec{u}_2)+a_2b_2f(\bvec{v}_2, \bvec{u}_2)
\end{aligned}
\end{equation}


In order to represent this map, we have to determine the bases for the two copies of $V$. They don't have to be the same base. Let's assume the base for the first $V$ is $\{\bvec{e}_i\}^n_{i=1}$, and for the second is $\{\bvec{e}_i'\}^n_{i=1}$. Now vectors in the two vector spaces can be represented by column matrices, and the 2-linear function by a square matrix: (example with a 2-dimesional $V$)
\begin{equation}\label{TestT_eq1}
\begin{aligned}
&\bvec{v}=a_1\bvec{e}_1+a_2\bvec{e}_2\rightarrow  \bvec c_v=\pmat{a_1\\a_2}\\
&\bvec{u}=b_1\bvec{e}'_1+b_2\bvec{e}'_2\rightarrow  \bvec c_u=\pmat{b_1\\b_2}\\
&f\rightarrow \bvec{M}=\pmat{f(\bvec{e}_1, \bvec{e}'_1)&f(\bvec{e}_1, \bvec{e}'_2)\\f(\bvec{e}_2, \bvec{e}'_1)&f(\bvec{e}_2, \bvec{e}'_2)}\\
\end{aligned}
\end{equation}


That way, we have $f(\bvec{v}, \bvec{u})= \bvec c_v^T\bvec{M} \bvec c_u$．Note that $\bvec c_v^T$ means the transpose of the matix $\bvec c_v$\footnote{If we use other bases, then the representations of $\bvec{v}$, $\bvec{u}$ and $f$ may be different matrices, but the calculation of $\bvec c_v^T\bvec{M} \bvec c_u$ doesn't change}．

\begin{exercise}{}
Think of the coordinate of a vector as a column matrix, then use to the laws of matrix calculation and substitute \autoref{TestT_eq1} into \autoref{TestT_eq2} to verify that $f(\bvec{v}, \bvec{u})= \bvec c_v^T\bvec{M} \bvec c_u$．
\end{exercise}


The example we just talked about is for 2-dimensional $V$. For n-dimensional $V$, $\bvec{M}$ becomes a $n\times n$ matrix, where the element in the ith row and jth column is $m_{ij}=f(\bvec{e}_i, \bvec{e}'_j)$．

Let's take a look at a simple 2-linear function. 

\begin{example}{Power}
The possible forces exerted on a point mass in the 3-dimensional space, make a 3-dimensional real vector space $V$. The possible velocities of this point mass alsk make a $V$\footnote{Recall: 2 vector spaces are isomorphic (equivalent) if and only if they are defined over a same field and have the same dimensions. }．Represent the force on the point by $\bvec{F}$, the velocity of the point by $\bvec{v}$, then the power of the force on the point is $P$, a 2-linear function: $P=\bvec{F}\cdot\bvec{v}$．If we determine the bases for the force space and the velocity space, we can also represent $\bvec{F}$ and $\bvec{v}$ as column matrices $c_F$ and $c_v$, respectively. Then, there is a matrix $\bvec{P}$ so that $P=c^T_F\bvec{P}c_v$. Here, $\bvec{P}$ is a 2-linear function that maps a force and a velocity to a power. If we choose the bases in the way: the base forces are along the positive directions of $x$, $y$ and $z$ with magnitude $1N$, and the base velocities are along the positive directions of $x$, $y$ and $z$ with magnitude $1\opn{m/s}$, then for these two bases, $\bvec{P}=\pmat{1&0&0\\0&1&0\\0&0&1}$；If we choose the base forces to be along the positive directions of $y$, $x$ and $z$, then $\bvec{P}$ becomes $\pmat{0&1&0\\1&0&0\\0&0&1}$. If, \textbf{again}, we change the base velocities to be along the positive directions of $x$, $z$ and $y$, then $\bvec{P}$ becomes $\pmat{0&0&1\\1&0&0\\0&1&0}$．
\end{example}



可以看到，功率函数把受力、速度两个向量映射为一个实数，功率．选定受力空间和速度空间的不同基，可以得到功率函数的不同矩阵表达．这些矩阵表达了功率函数的特点，却随着基的变化而变化．类比线性代数中所学的线性映射，都可以表示为一个矩阵，虽然矩阵随着基的选取的不同可能也会不同，但是这些矩阵都表示同一个线性映射．同样，我们也可以把功率函数看成本身不变的，只是其矩阵表示随着基的选取不同而可能不同．

\subsubsection{矩阵的运算回顾}

为了方便推广$2$-线性函数的概念，我们需要用到向量矩阵的概念，因此要简单回顾一下矩阵运算．

矩阵只是一种运算的表达方式．虽然我们常见的矩阵元素都是实数或者复数，但是只要是可以相加和相乘的元素都可以当作矩阵元素．

\begin{example}{矩阵运算的例子}

\begin{itemize}
%
\item 向量可以和数字相乘．如果$\bvec{v}_i$表示向量，$a_i$表示数字，那么$\pmat{\bvec{v}_1&\bvec{v}_2&\bvec{v}_3}$是三个向量排成的矩阵，$\pmat{a_1\\a_2\\a_3}$是三个数字排成的矩阵，按照向量的数乘来进行矩阵乘法，$\pmat{\bvec{v}_1&\bvec{v}_2&\bvec{v}_3}\pmat{a_1\\a_2\\a_3}=(a_1\bvec{v}_1+a_2\bvec{v}_2+a_3\bvec{v}_3)$就是一个向量，而$\pmat{a_1\\a_2\\a_3}\pmat{\bvec{v}_1&\bvec{v}_2&\bvec{v}_3}=\pmat{a_1\bvec{v_1}&a_1\bvec{v_2}&a_1\bvec{v_3}\\a_2\bvec{v_1}&a_2\bvec{v_2}&a_2\bvec{v_3}\\a_3\bvec{v_1}&a_3\bvec{v_2}&a_3\bvec{v_3}}$是$9$个向量排成的矩阵．
\item 向量之间可以有点乘．因此$\pmat{\bvec{v}_1&\bvec{v}_2\\\bvec{v}_3&\bvec{v}_4}\cdot\pmat{\bvec{v}_5\\\bvec{v}_6}=\pmat{\bvec{v}_1\cdot\bvec{v}_5+\bvec{v}_2\cdot\bvec{v}_6\\\bvec{v}_3\cdot\bvec{v}_5+\bvec{v}_4\cdot\bvec{v}_6}$是两个数字排成的矩阵．
\item 3维向量之间可以有叉乘．因此$\pmat{\bvec{v}_1&\bvec{v}_2\\\bvec{v}_3&\bvec{v}_4}\times\pmat{\bvec{v}_5\\\bvec{v}_6}=\pmat{\bvec{v}_1\times\bvec{v}_5+\bvec{v}_2\times\bvec{v}_6\\\bvec{v}_3\times\bvec{v}_5+\bvec{v}_4\times\bvec{v}_6}$是两个向量排成的矩阵．
%
\end{itemize}
\end{example}




