% 计算机视觉（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Maxwell\%27s_equations}{相关文章}。

计算机视觉任务包括获取、处理、分析和理解数字图像的方法，以及从现实世界中提取高维数据，以产生数值或符号信息，例如决策的形式。[1][2][3][4] 在这个上下文中，“理解”意味着将视觉图像（即输入到视网膜的图像）转化为世界的描述，这些描述对思维过程有意义，并能够引发适当的行动。这种图像理解可以看作是通过几何学、物理学、统计学和学习理论的帮助，使用模型从图像数据中解开符号信息。

计算机视觉这一科学学科关注的是从图像中提取信息的人工系统背后的理论。图像数据可以呈现多种形式，如视频序列、来自多个摄像头的视角、来自3D扫描仪的多维数据、来自LiDAR传感器的3D点云，或医学扫描设备的数据。计算机视觉的技术学科旨在将其理论和模型应用于计算机视觉系统的构建。

计算机视觉的子学科包括场景重建、物体检测、事件检测、活动识别、视频追踪、物体识别、3D姿态估计、学习、索引、运动估计、视觉伺服、3D场景建模和图像修复。
\subsection{定义}  
计算机视觉是一个跨学科领域，研究如何让计算机从数字图像或视频中获得高级理解。从工程的角度来看，它旨在自动化人类视觉系统能够完成的任务。[5][6][7] “计算机视觉关注的是从单张图像或图像序列中自动提取、分析和理解有用信息。它涉及开发理论和算法基础，以实现自动的视觉理解。”[8] 作为一门科学学科，计算机视觉关注的是从图像中提取信息的人工系统背后的理论。图像数据可以有多种形式，如视频序列、来自多个摄像头的视角，或来自医学扫描仪的多维数据。[9] 作为一门技术学科，计算机视觉旨在将其理论和模型应用于计算机视觉系统的构建。机器视觉则指的是一个系统工程学科，特别是在工厂自动化的背景下。近年来，计算机视觉和机器视觉这两个术语在一定程度上趋于融合。[10]: 13 
\subsection{历史}  
在20世纪60年代末，计算机视觉在那些开创人工智能的大学中开始发展。它的目标是模仿人类视觉系统，作为赋予机器人智能行为的垫脚石。[11] 1966年，人们认为这一目标可以通过一个本科生的暑期项目来实现，即将相机连接到计算机，并让计算机“描述它所看到的内容”。[12][13][14]

当时，计算机视觉与数字图像处理领域的主要区别在于，它希望从图像中提取三维结构，目的是实现完整的场景理解。1970年代的研究为许多如今存在的计算机视觉算法奠定了早期基础，包括从图像中提取边缘、标记线条、非多面体和多面体建模、将物体表示为小结构的相互连接、光流和运动估计等。[11]

接下来的十年，计算机视觉的研究逐渐转向更加严格的数学分析和定量方法。这些研究包括尺度空间的概念、从各种线索（如阴影、纹理和焦点）推断形状，以及称为“蛇形模型”的轮廓模型。研究人员还意识到，许多这些数学概念可以在同一个优化框架内处理，类似于正则化和马尔可夫随机场的应用。[15] 到了1990年代，一些之前的研究主题变得比其他主题更为活跃。投影三维重建方面的研究加深了对相机标定的理解。随着相机标定优化方法的出现，人们意识到，很多这些想法已经在摄影测量学中的束调整理论中被探索过。这催生了多张图像的稀疏三维重建方法。同时，图割算法的变种被用来解决图像分割问题。本十年还标志着统计学习技术首次被应用于图像中的人脸识别（参见Eigenface）。到1990年代末，计算机图形学与计算机视觉领域的互动大幅增加，这带来了图像基础渲染、图像变形、视角插值、全景图像拼接以及早期的光场渲染技术。[11]

近年来，基于特征的方法与机器学习技术及复杂优化框架结合使用，得到了复兴。[16][17] 深度学习技术的进步为计算机视觉领域注入了新的活力。深度学习算法在多个标准计算机视觉数据集上的准确性，已经超越了以前的方法，这些任务包括分类、分割和光流等。[19]
\subsection{Related fields}
\subsubsection{固态物理}  
\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/e25fe3638cea36a0.png}
\caption{照片中的物体检测} \label{fig_JSJ_1}
\end{figure}
固态物理是与计算机视觉密切相关的另一个领域。大多数计算机视觉系统依赖于图像传感器，这些传感器检测电磁辐射，通常表现为可见光、红外光或紫外光。传感器的设计基于量子物理学。光与表面的相互作用过程通过物理学来解释。物理学还解释了光学行为，而光学是大多数成像系统的核心部分。复杂的图像传感器甚至需要量子力学来提供对图像形成过程的完整理解。[11] 此外，物理学中的各种测量问题也可以通过计算机视觉来解决，例如流体中的运动。
\subsubsection{神经生物学}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/749b3524c551dca7.png}
\caption{物体检测中训练神经网络的简化示例：该网络通过多张已知包含海星和海胆的图像进行训练，这些图像与表示视觉特征的“节点”相关联。海星匹配有环形纹理和星形轮廓，而大多数海胆则匹配有条纹纹理和椭圆形状。然而，具有环形纹理的海胆实例在它们之间创建了一个较弱的权重关联。} \label{fig_JSJ_2}
\end{figure}
\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/380ed3697dbafa56.png}
\caption{网络在输入图像上的后续运行（左图）：[20] 网络正确地检测到了海星。然而，环形纹理与海胆之间的弱权重关联也通过两个中间节点中的一个向海胆传递了一个弱信号。此外，训练中未包含的贝壳对椭圆形状也产生了一个弱信号，导致海胆输出的弱信号。这些弱信号可能导致海胆的假阳性结果。实际上，纹理和轮廓不会通过单一节点来表示，而是通过多个节点的相关权重模式来表示。} \label{fig_JSJ_3}
\end{figure}
神经生物学对计算机视觉算法的发展产生了深远影响。在过去的一个世纪里，科学家对人类和各种动物的眼睛、神经元和大脑结构进行了广泛研究，重点是视觉刺激的处理。这些研究为理解自然视觉系统如何解决某些与视觉相关的任务提供了粗略而复杂的描述。这些成果促成了计算机视觉的一个子领域，旨在设计人工系统，模仿生物系统在不同复杂度层次上的处理和行为。此外，计算机视觉中一些基于学习的方法（例如，基于神经网络和深度学习的图像与特征分析与分类）也有其神经生物学背景。由福岛邦彦在1970年代开发的神经网络——新认知论（Neocognitron）就是一个早期的例子，展示了计算机视觉如何直接借鉴神经生物学，特别是初级视觉皮层的工作原理。

一些计算机视觉研究方向与生物学视觉研究密切相关——事实上，就像许多人工智能研究与人类智能以及利用存储知识来解释、整合和利用视觉信息的研究紧密相连一样，生物学视觉领域研究和模型化了人类及其他动物的视觉感知生理过程。与此不同，计算机视觉则开发并描述了实现人工视觉系统的软件和硬件中的算法。生物学与计算机视觉之间的跨学科交流对两者都取得了有益的成果。
\subsubsection{信号处理}  
与计算机视觉相关的另一个领域是信号处理。许多用于处理单变量信号（通常是时间信号）的方法，可以自然地扩展到计算机视觉中处理二维或多变量信号。然而，由于图像的特定性质，计算机视觉中有许多方法在单变量信号处理领域中是没有对等方法的。加上信号的多维性，这就定义了信号处理中的一个子领域，作为计算机视觉的一部分。
\subsubsection{机器人导航}  
机器人导航有时涉及自主路径规划或机器人系统在环境中导航的推理。[22] 要在环境中导航，需要对这些环境有详细的理解。关于环境的信息可以通过计算机视觉系统提供，该系统作为视觉传感器，提供关于环境和机器人自身的高层次信息。
