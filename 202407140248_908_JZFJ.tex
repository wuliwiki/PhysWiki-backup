% 矩阵分解
% license CCBYSA3
% type Wiki

（本文根据 CC-BY-SA 协议转载自原搜狗科学百科对英文维基百科的翻译）

矩阵分解是推荐系统中使用的一类协同过滤算法。矩阵分解算法通过将用户-项目交互矩阵分解成两个低维矩形矩阵的乘积来工作[1]。 由于西蒙·芬克在他2006年的博客文章中报道了这一系列方法的有效性，并与研究团体分享了他的发现[2]，从而这一系列方法在Netflix奖挑战赛中广为人知。

\subsection{技术}
矩阵分解背后的思想是在较低维度的隐空间中表示用户和物品。自从Funk在2006年的第一次工作以来，业界已经为推荐系统提出了许多矩阵分解方法。下面列出了一些最常用和最简单的方法。
\subsubsection{1.1 Funk SVD}
西蒙·芬克(Simon Funk)在其博客中提出的原始算法是将用户-物品评分矩阵分解为两个较低维矩阵的乘积，第一个矩阵为每个用户一行，第二个矩阵为每个物品一列。与特定用户或物品相关联的行或列称为隐因子。

请注意，尽管它的名字叫做SVD，但是在FunkSVD中并没有应用奇异值分解。预测评分可以通过公式计算：$\tilde{\mathbf{R}} = \mathbf{H} \mathbf{W}$，其中 $\tilde{\mathbf{R}} \in \mathbb{R}^{\text{users} \times \text{items}}$ 是用户-物品评分矩阵，$\mathbf{H} \in \mathbb{R}^{\text{users} \times \text{latent factors}}$ 包含用户的隐因子和 $\mathbf{W} \in \mathbb{R}^{\text{latent factors} \times \text{items}}$ 该物品的隐因子。

具体地来说，用户 $u$ 对物品 $i$ 给出的预测评分计算如下：
$$\tilde{r}_{ui} = \sum_{f=0}^{n_{\text{factors}}} H_{u,f} W_{f,i}~$$
可以通过改变隐因子的数量来调整模型的表达能力。已经证明 [4] 具有一个潜在因素的矩阵分解相当于“最受欢迎”的推荐器(例如，推荐具有最多交互而没有任何个性化的项目)。增加潜在因素的数量将提高个性化，从而提高推荐质量，直到因素的数量变得过高，这时模型开始溢出，推荐质量将下降。避免过度拟合的常见策略是在目标函数中添加正则项。FunkSVD是作为一个评分预测问题开发的，因此它使用明确的数字评分作为用户-项目交互信息。

综上所述，FunkSVD最小化以下目标函数:
\begin{equation}
\arg \min_{H, W} \|\mathbf{R} - \tilde{\mathbf{R}}\|_F + \alpha \|\mathbf{H}\| + \beta \|\mathbf{W}\|~
\end{equation}

其中 \(\|\cdot\|_F\) 被定义为 Frobenius 范数，而其余的范数可能是 Frobenius 范数，也可能是其他范数，这取决于具体的推荐问题。
\subsubsection{1.2 SVD++}
虽然FunkSVD能够提供非常好的推荐质量，但它在表示用户-物品交互时仅使用明确的数字评级这一方法具有局限性。现代推荐系统应该利用所有可用的交互信息，包括显式的(例如数字评分)和隐式的(例如喜欢、购买、跳过、书签)。为此，SVD++被设计成考虑隐式交互的模型[6][7]。与FunkSVD相比，SVD++还考虑了用户和物品偏好。

用户 $u$ 对项目 $i$ 的预测评分计算如下：

$$\tilde{r}_{ui} = \mu + b_i + b_u + \sum_{f=0}^{n_{\text{factors}}} H_{u,f} W_{f,i}~$$

其中：
- $\mu$ 是全局平均评分
- $b_i$ 是项目 $i$ 的偏置
- $b_u$ 是用户 $u$ 的偏置
- $H_{u,f}$ 是用户 $u$ 在因子 $f$ 上的隐因子
- $W_{f,i}$ 是项目 $i$ 在因子 $f$ 上的隐因子