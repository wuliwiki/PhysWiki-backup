% 人工神经网络（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=6cm]{./figures/9fddb6b4ea5a9fd3.png}
\caption{人工神经网络是一个互相连接的节点群，灵感来源于大脑中神经元的简化模型。在这里，每个圆形节点代表一个人工神经元，箭头代表从一个人工神经元的输出到另一个人工神经元输入的连接。} \label{fig_RGSJ_1}
\end{figure}
在机器学习中，神经网络（也称为人工神经网络或神经网，缩写为ANN或NN）是一种受到动物大脑生物神经网络结构和功能启发的模型。[1][2]

一个人工神经网络由连接的单元或节点组成，这些节点被称为人工神经元，粗略地模拟大脑中的神经元。这些神经元通过边（连接）相互连接，模拟大脑中的突触。每个人工神经元接收来自连接神经元的信号，然后处理这些信号并将结果传送给其他连接的神经元。这个“信号”是一个实数，每个神经元的输出通过某个非线性函数计算，该函数作用于输入的和，这个过程被称为激活函数。每个连接的信号强度由一个权重决定，权重会在学习过程中调整。

通常，神经元会被聚合成层。不同的层可能对其输入执行不同的变换。信号从第一层（输入层）传输到最后一层（输出层），可能会经过多个中间层（隐藏层）。如果一个网络至少有两个隐藏层，通常称其为深度神经网络。[3]

人工神经网络被用于各种任务，包括预测建模、自适应控制和解决人工智能中的问题。它们能够从经验中学习，并能够从复杂且看似不相关的信息集中推导结论。
\subsection{训练}
神经网络通常通过经验风险最小化进行训练。这种方法基于优化网络参数，以最小化预测输出与给定数据集中的实际目标值之间的差异或经验风险的理念。[4] 基于梯度的方法，如反向传播，通常用于估计网络的参数。[4] 在训练阶段，人工神经网络通过标记的训练数据进行学习，通过迭代更新参数以最小化定义的损失函数。[5] 这种方法使得网络能够对未见过的数据进行泛化。
\subsection{历史}  
\subsubsection{早期工作}  
今天的深度神经网络基于200多年前统计学的早期工作。最简单的前馈神经网络（FNN）是一个线性网络，它由一层输出节点组成，节点使用线性激活函数；输入通过一系列权重直接馈送到输出。在每个节点上，输入和权重的乘积之和会被计算出来。通过对这些计算的输出与给定目标值之间的均方误差进行最小化，调整权重。这种技术已经有两个多世纪的历史，被称为最小二乘法或线性回归。它由勒让德（1805年）和高斯（1795年）用于预测行星运动，通过找到一组点的最佳线性拟合。[7][8][9][10][11]  

历史上，像冯·诺依曼模型这样的数字计算机通过执行显式指令并通过多个处理器访问内存来操作。另一方面，一些神经网络起源于试图通过联结主义框架模拟生物系统中的信息处理。与冯·诺依曼模型不同，联结主义计算不将内存和处理分开。  

沃伦·麦卡洛克和沃尔特·皮茨（1943年）考虑了一个非学习型的神经网络计算模型。[13] 这个模型为神经网络研究分裂成两种不同的方向奠定了基础。一种方向专注于生物过程，而另一种方向则专注于神经网络在人工智能中的应用。

在20世纪40年代末，D.O. Hebb[14] 提出了一个基于神经可塑性机制的学习假设，这个假设后来被称为赫布学习（Hebbian learning）。它被用于许多早期的神经网络中，例如Rosenblatt的感知器和霍普菲尔德网络。Farley和Clark[15]（1954年）使用计算机模拟了一个赫布网络。其他神经网络计算机器由Rochester、Holland、Habit和Duda（1956年）创建。[16]  

1958年，心理学家Frank Rosenblatt描述了感知器，这是一种最早实现的人工神经网络之一，[17][18][19][20] 由美国海军研究办公室资助。[21] R.D. Joseph（1960年）[22] 提到Farley和Clark（1956年）开发的早期感知器类设备：[10] "麻省理工学院林肯实验室的Farley和Clark实际上在感知器类设备的开发上先于Rosenblatt。" 然而，他们“放弃了这个课题。”感知器引发了公众对人工神经网络研究的热情，促使美国政府大幅增加资金。这为计算机科学家对感知器能够模拟人类智能的乐观预期提供了支持，进一步推动了“人工智能的黄金时代”。[23]  

最初的感知器没有自适应的隐藏单元。然而，Joseph（1960年）[22] 也讨论了具有自适应隐藏层的多层感知器。Rosenblatt（1962年）[24]: 第16节 引用并采纳了这些想法，同时也给出了H.D. Block和B.W. Knight的工作。然而，这些早期的努力并未导致隐藏单元的有效学习算法，也就是深度学习的实现未能成功。


1960年代和1970年代的深度学习突破

在1960年代和1970年代，人工神经网络（ANNs）进行了基础研究。第一个有效的深度学习算法是数据处理组方法（Group Method of Data Handling），这是一个用于训练任意深度神经网络的方法，由Alexey Ivakhnenko和Lapa于苏联（1965年）提出。他们将其视为一种多项式回归方法，[25] 或者说是Rosenblatt感知器的推广。[26] 1971年的一篇论文描述了一个由这种方法训练的八层深度网络，[27] 该方法基于通过回归分析逐层训练的方式。通过使用单独的验证集修剪冗余的隐藏单元。由于节点的激活函数是Kolmogorov-Gabor多项式，这些也成为了第一个具有乘法单元或“门”的深度网络。[10]

第一个通过随机梯度下降（SGD）训练的深度学习多层感知器（MLP）由Shun'ichi Amari于1967年发布。[29] 在Amari的学生Saito进行的计算机实验中，一个具有五层的多层感知器（MLP）通过修改两层的方式学习了内部表示，用于对非线性可分模式类别进行分类。[10] 随着硬件和超参数调优的发展，端到端的随机梯度下降目前已成为主流的训练技术。

1969年，Kunihiko Fukushima引入了ReLU（修正线性单元）激活函数。[10][30][31] 修正器成为了深度学习中最流行的激活函数。[32]

尽管如此，在美国的研究在Minsky和Papert（1969年）的工作之后停滞不前，[33] 他们强调基础感知器无法处理异或（exclusive-or）电路。这个洞察对Ivakhnenko（1965年）和Amari（1967年）的深度网络并不适用。

1976年，迁移学习在神经网络学习中被引入。[34][35]

深度学习架构用于卷积神经网络（CNNs），包括卷积层、降采样层和权重复制，始于Kunihiko Fukushima于1979年引入的Neocognitron，尽管该网络并未通过反向传播进行训练。[36][37][38]