% 交叉验证
% keys 交叉验证|模型评估
% license Xiao
% type Tutor


\pentry{模型评估\nref{nod_MoEva}，数据\nref{nod_datast}}{nod_eaba}

\textbf{交叉验证}（Cross validation）是机器学习中的一种模型评估方法。该方法将数据划分成多个部分，然后轮流使用每个部分作为测试集，另一个部分作为训练集，多次训练和测试之后得出模型的平均性能。

如果把数据划分成k份，我们就称此时的验证方法为\textbf{k-折交叉验证}（k-fold cross validatioin）。详细过程是，将数据集分成 k 份，然后进行 k 次训练和测试，每次使用不同的 k-1 份数据作为训练集，剩余的一份数据作为测试集，最终得到 k 个性能指标的平均值。通过使用交叉验证，可以减少过拟合的风险，并提高模型的泛化能力。

\begin{figure}[ht]
\centering
\includegraphics[width=14.25cm]{./figures/a680b2bff656ad1d.png}
\caption{十折交叉验证示意图} \label{fig_CroVal_1}
\end{figure}
图1所表示的是十折交叉验证的过程。图中红色表示的是被用于测试的数据，其它部分均为训练数据。每次轮流选择一部分作为测试集，依次为：$D10$、$D9$,...$D1$，训练测试完之后得到一个模型性能的结果，最后取得一个平均值作为最后模型性能的评估结果。

交叉验证法的优势是使得训练数据中的每一个样本都被用于训练模型。弥补了\enref{留出法}{holdou}通常只能使用一部分数据用于训练的不足。

特别地，如果每次训练和测试时，只留一个样本作为测试，其余样本全部用于模型训练，那么，此时的交叉验证方式就称为\textbf{留一法}（leave-one-out, LOO）。留一法的优势是最大可能地使用了原始数据集来训练模型，使得训练出来的模型能够更好地拟合原数据。但是，这会带来一个问题，就是该模型的测试准确度可能有较大偏差，因为每次只有一个测试样本。


\subsection{编程实战}

给出一段实现了5折交叉验证的示例程序。程序训练了一个逻辑回归分类器，然后用5折交叉验证的方法评价了模型的分类准确率。算法基于scikit-learn机器学习库实现。

\subsubsection{代码示例}
\begin{lstlisting}[language=python]
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold, cross_val_score


# 加载数据集
data = load_iris()
X = data.data
y = data.target

# 定义模型
model = LogisticRegression(max_iter=200)

# 定义k折交叉验证
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# 评估模型性能
scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')

# 输出结果
print("交叉验证的准确率：", scores)
print("平均准确率：", scores.mean())
\end{lstlisting}
上述程序首先下载了iris公开数据集，然后训练一个逻辑回归分类器。

\subsubsection{结果与说明}
程序执行结果如下：
\begin{lstlisting}[language=none]
交叉验证的准确率： [1. 1. 0.93333333 0.96666667 0.96666667]
平均准确率： 0.9733333333333334
\end{lstlisting}
