% CUDA 基础笔记

\begin{itemize}
\item 所有有 CUDA 语法的源文件都用 \verb`.cu` 后缀, 否则会报错 (包括 include 的头文件中的 cuda 语法)!
\item \verb`cudaGetDeviceCount(int *deviceCount)` 可以返回 GPU 的数量.
\item \verb`cudaSetDevice(int device)` 用于切换 GPU, 其中 device 是 GPU 的编号, 从 0 开始. 默认的 GPU 编号是 0.
\item \verb`cudaGetDeviceProperties(struct cudaDeviceProp * prop, int device)` 可以获取 GPU 信息. prop 中常用的 member 如下:
\verb`prop.name` 是 GPU 型号 (名称), \verb`prop.major` 是 capability 的编号, 每个编号是一种构架, 3: Kepler,  5: Maxwell, 6: Pascal, 7: Volta, prop.minor 是 capability 的小数点后的编号, \verb`prop.multiProcessorCount` 是 multiprocessor 的数量, 总核数等于该数量乘以每个 mp 中的核数 (与构架有关), \verb`prop.deviceOverlap` 表示 GPU 是否有同时执行 kernel 和传数据的能力, 只有这个能力存在, 用多个 stream 才有可能加速.
\verb`prop.totalGlobalMem` 和 \verb`prop.totalConstMem` 分别是 GPU 内存的大小和 const 空间的大小. \verb`prop.canMapHostMemory` 决定 GPU 是否能使用 zero-copy memory. 剩下的见 cudaDeviceProp 的定义.
\item kernel function 如果在 runtime 时出错了, 应该是会终止而不会与任何报错的, 所以在 nvprof 里面应该就看不到 kernel 了. 但如果能看到, 应该就是执行成功了.
\item 许多 \verb`cuda*()` 函数都会返回错误类型 \verb`cudaError_t`, \verb`cudaGetErrorString(cudaError_t err)` 可以返回错误的描述.
\item \verb`cudaDeviceSynchronize()` 函数在使 host 程序等待所有 device 完成任务.
\item \verb`__syncthreads()` 函数在 kernel 中的所有 thread 同步.
\item pascal 6.0: 64 cores/Multiprocessor, 6.1: 128 cores/Multiprocessor.   volta 7.0: 64 cores/Multiprocessor
\item pascal 构架的 shared memory 是 48kb/block (6144 个 double), volta 构架是 96kb/block. 如果超出, 编译的时候会报错.
\item 在 global scope 声明的 const (不是 \verb`__constant__`) 变量既可以在 host code 中也可以在 device code 中使用.
\item 在 global scope 声明的变量前面加 \verb`__device__` , 则该 global 变量只能用于 device code, 不能在 host 中使用, 但可以在 host 中用 \verb`cudaMemcpyToSymbol()` 对其赋值. 如果改用 \verb`__cnstant__`, 则只能在 device code 中读取该变量, 但同样可以在 host 中用 \verb`cudaMemcpyToSymbol()`. \verb`__constant__` 空间一般只有 64kb, 但有可能将速度变快 (见 cuda by examples).
\item \verb`__device__`, \verb`__constant__`, 支持特定的 class object, 这个 class 必须要有一个空的 constructor 或者没有 constructor (默认).

\item 如果 class 的成员函数需要在 kernel 中执行, 前面要加 \verb`__device__`, 如果要在 kernel 和 host 中执行, 前面要加 \verb`__host__ __device__`.
\item kernel 里面是可以用 \verb`new` 和 \verb`delete` 的, 也可用 \verb`malloc()` 和 \verb`free()` ! 使用的是 device 空间的储存, 在一块专门的区域叫做 heap. 如果不够的话, \verb`new` 会返回 \verb`nullptr`. （貌似不一定！）
\item heap size 默认是 8M, 但也可以手动设置大小.
\begin{lstlisting}[language=cpp]
cudaDeviceGetLimit(size_t* size, cudaLimitMallocHeapSize)  // 获取 heap size
cudaDeviceSetLimit(cudaLimitMallocHeapSize, size_t size) // 设置 heap size
\end{lstlisting}
\item 如果每个线程都用 \verb`new`，貌似消耗的 heap 空间会随 block 数量不断增长，而不是与 cuda core 的数量成正比．而且 heap 不够的时候不会报错，而是整个 kernel 都不执行.
\item 在 Tesla V100 上, 用 \verb`cudaMalloc()` 代替 new, 速度要快许多,  然而 Quadro P5000 反而会慢, 但是慢的不多.
\item 要在 cuda 中使用 complex, 用 \verb`#include "cuda_complex.h"` , 见我的 CUDATest/template.
\item 执行一个 parallel for 类似的问题时, 最好是安排每个线程执行 for(i=ind; i<N; i+=Nblock*Nthread)，而千万不要企图用大量的 block 使得每个线程只用执行一个 i.
\item 如果每个线程都是完全独立的话, 貌似在 Tesla V100 上用 <<<2*Ncore/32,32>>> 所需的时间最短, 总线程数是 2*Ncore = 10240. (这个结论是用 cn3Dz 得出的).
\item 用 Even 给 GPU 计时:
\begin{lstlisting}[language=cpp]
cudaEven_t start, stop;
cudaEventCreate(&start); cudaEventCreate(&stop);
cudaEventRecord(start, 0);
// do some work on the GPU
cudaEventRecord(stop, 0);
cudaEventSynchronize(stop); // let CPU wait for the event to finish
cudaEventElapsedtime(&elapsedTime, start, stop); // time unit is "ms"
cudaEventDestroy(start); cudaEventDestroy(stop);
\end{lstlisting}

\subsection{不同的 Memory}
\item \verb`malloc()` 分配 pageable host memory, 而 \verb`cudaHostAlloc(void** pointer, size_t size, cudaHostAllocDefault)` 分配 page-locked host memory (或 pinned memory). 后者不会被 swap 到硬盘中. 要释放后者分配的内存, 用 \verb`cudaFreeHost(void * pointer)` 即可. page-locked 内存在 CPU 和 GPU 间的传输速度大概是 pageable 内存的两倍.
\item 如果用 \verb`cudaHostAlloc(void** pointer, size_t size, cudaHostAllocMapped)`, 分配出来的内存就是 zero-copy memory, 因为这种内存可以直接在 kernel code 中读取.
\item 要使用 zero-copy memory, 开始时需要在 host 程序中用 \verb`cudaSetDeviceFlags(cudaDeviceMapHost)`.
\item 当 zero-copy memory 内存只用于 GPU 时, 选项 \verb`cudaHostAllocMapped | cudaHostAllocWriteCombined` 可以提升性能.
\item \verb`cudaHostGetDevicePointer(void **pDevice, void *pHost, 0)` 函数用于将 zero-copy memory 从 Host 中的指针得到 Device 的指针.
\item 调用 kernel 后, zero-copy memory 会变成 undefined. 使用 \verb`cudaThreadSynchronize()` 即可恢复.
\end{itemize}
