% 数值计算的误差

\subsection{误差}
误差（Errors）的基本概念在高中物理里面应该有所涉及，这里就不仔细展开了． 对于科学计算而言，我们所关注的主要是\textbf{相对误差(relative error)}和\textbf{绝对误差(absolute error)}．

如果我们把一个数据的实际值记做 $x$ , 把它的近似值记为 $\hat x$． 在这个近似的过程，误差产生的原因主要有：
\begin{itemize}
\item 测量中的误差
\item 运算和计算机表达中的不精确所引入的机器误差或者舍入误差（round-off error）
\item 数值方法和离散化带来的误差（discretization error）
\end{itemize}
尤其是后面两种，是科学计算中要面临的两个主要的误差来源，下面我们会对它们进行逐一分析． 因此，在评估和使用数值方法时，我们需要系统的衡量这两项误差，并且要\textbf{掌握它们的来源}，对它们的\textbf{大小有足够的控制}．

\subsection{范数}
在了解误差以前，我们先来回顾一下线性代数中的一个常规概念，范数．

科学计算中经常会涉及到向量（vector），矩阵（matrix）和张量（tensor）． 计算与它们有关的误差，需要使用更为一般化的“绝对值”函数，也就是范数 $\norm{\cdot}$．

下面是几个常见的范数，其中向量由小写字母表示，矩阵由大写字母表示．
\begin{itemize}
\item 1-范数：  $\|v\|_1=(|v_1|+|v_2|+\cdots+|v_N|)$
\item 2-范数：  $\|v\|_2=(v_1^2+v_2^2+\cdots+v_N^2)^{\frac{1}{2}}$
\item p-范数：  $\|v\|_p=(v_1^p+v_2^p+\cdots+v_N^p)^{\frac{1}{p}},\quad p>0$
\item $\infty$  -范数，  $\|v\|_{\infty}=\max_{1\le i \le N}|v_i|$
\item 矩阵的p-范数：  $\|A\|p=\max_{\|u\|_p=1}\|Au\|_p$
\item Frobenius-范数：  $\|A\|_F=(\sum_{i=1}^m\sum_{j=1}^n|a_{ij}|^2)^{\frac{1}{2}}$
\end{itemize}

这些范数可以用 Matlab 的 \verb|norm()| 函数或者用 Python 中的 \href{https%3A//docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html}{numpy.linalg.norm} 函数进行计算． 那么绝对误差的用范数表达式为  $\epsilon=\|x-\hat{x}\|$  ，相对误差为  $\tau=\frac{\|x-\hat{x}\|}{\|x\|}$  ．

例子1：  \verb|absrelerror(corr, approx)| 函数使用默认的2-范数，计算 \verb|corr| 和 \verb|approx| 之间的绝对和相对误差．




舍入误差（Round-off error）

舍入误差，有时也称为机器精度（machine epsilon），简单理解就是<b>由于用计算机有限的内存来表达实数轴上面无限多的数，而引入的近似误差．

换一个角度来看，这个误差应该不超过计算机中可以表达的相邻两个实数之间的间隔． 通过一些巧妙的设计，例如

这个间隔的绝对值可以随计算机所要表达的值的大小变化，并始终保持它的相对值在一个较小的范围． 关于浮点数标准，我们会在后面的一章 “<i>计算机算术”</i>里面具体解释和分析．

例子2：机器精度

使用之前定义的 \verb|absrelerror()| 函数，在 Python3 环境下，运行下面的程序．

由上面两个例子可以观察到，机器精度约为  $10^{-16}$． 值得注意的是，在例子2中， 如果我们直接令 \verb|b=1/3| ，再求和，则不会得到任何误差． 事实上，这个舍入误差出现在 \verb|b=a-1| 时，并且延续到了后面的求和计算． 而对于例子3，求和时当两个数的相对大小差距超过  $10^{-16}$  （或  $10^{16}$  ）时，较小的数的贡献会消失．这种现象在有些地方也被称作cancellation error． 事实上，它只是舍入误差的一种表现． 至于具体的原理，也会在后面计算机算术这一章和浮点数标准中详细介绍．</p><h3>例子4: 矩阵运算中的误差</h3><p>下面定义一个测试函数 \verb|testErrA(n)| ，随机生成  $n\times n$  矩阵  $A$  ，然后计算  $A^{-1}A$  与单位矩阵  $I$  之间的误差．

理论上，这两个值应该完全相等，但是由于存在舍入误差， $A^{-1}A$ 并不完全等于单位矩阵．</p><div class="highlight"><pre><code class="language-python"><span class="c1"># Generate a random nxn matrix and compute A^{-1}*A which should be I analytically</span>
<span class="k">def</span> <span class="nf">testErrA</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">Icomp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">A</span><span class="p">)</span>
    <span class="n">Iexact</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">absrelerror</span><span class="p">(</span><span class="n">Iexact</span><span class="p">,</span> <span class="n">Icomp</span><span class="p">)</span>| </pre></div><p>调用函数可得到类似如下的输出：</p><div class="highlight"><pre><code class="language-pycon">testErrA()
*----------------------------------------------------------*
This program illustrates the absolute and relative error.
*----------------------------------------------------------*
Absolute error: 6.626588434229317e-15
Relative error: 2.095511256869353e-15| </pre></div><p>由于矩阵  $A$  的随机性，这里的输出并不会完全一致，但相对误差始终保持在 $10^{-14}$  至  $10^{-16}$  这个范围． 我们也可以尝试不同大小的矩阵，误差也会随着矩阵尺寸变大而增大．

<b>注1</b>：对于矩阵求逆运算的机器精度估算，涉及到矩阵的条件数（condition number），这个会在后面求解线性方程时具体分析．

<b>注2</b>：矩阵求逆的运算复杂度约为  $\mathcal{O}(n^2)$  或以上，因此继续增大  $n$  有可能会让程序的运行时间大大增加．</p><h2>离散化误差（Discretization error）</h2><p>顾名思义，是由数值方法的离散化所引入的误差．通常情况下，离散化误差的大小与离散化尺寸直接相关． 以前向差分（forward difference）为例，函数  $f(x)$  的一阶导数可以近似为：

 $ f'(x)\approx \frac{f(x+h)-f(x)}{h}，\\$  

其中，  $h$  为网格尺寸或步长． 通过泰勒展开（Taylor expansion）可知，前向差分的离散化误差为 $\mathcal{O}(h)$，% 即每当 $h$ 缩小到它的一半，则误差也相应的缩小一半．

类似的，对于中央差分（central difference）和五点差分（five-points difference）

 $f'(x)\approx \frac{f(x+h)-f(x-h)}{2h}，\\$  

 $f'(x)\approx \frac{-f(x+2h)+8f(x+h)-8f(x-h)+f(x-2h)}{12h}.\\ $ 

它们的离散化误差分别为 $\mathcal{O}(h^2)$ 和  $\mathcal{O}(h^4)$  ．对应的，%当  $h$  缩小一半，误差分别变为原来的 1/4和1/16．</p><h3>例子5: 前向差分的离散化误差</h3><p>取  $f(x)=e^x$  ，可知  $f'(x)=e^x$  ．我们用前向差分来计算  $f(x)$  的一阶导数，把它们的值和真实值对比，并分别画出  $h=0.2, 0.1$  和  $0.05$  的结果．</p><div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">ForwardDiff</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="c1"># ForwardDiff(@fx, x, h);</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">h</span>

<span class="k">def</span> <span class="nf">testDiscretization</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># compute the numerical derivatives</span>
    <span class="n">xh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">u</span><span class="o">-</span><span class="n">l</span><span class="p">)</span><span class="o">/</span><span class="n">h</span><span class="p">))</span>
    <span class="n">fprimF</span> <span class="o">=</span> <span class="n">ForwardDiff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">xh</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xh</span><span class="p">,</span> <span class="n">fprimF</span>

<span class="c1"># The exact solution</span>
<span class="n">Nx</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Nx</span><span class="p">)</span>
<span class="n">f_exa</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">w_pad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">h_pad</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">axs</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f_exa</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">)</span>
    <span class="n">xh</span><span class="p">,</span> <span class="n">fprimF</span> <span class="o">=</span> <span class="n">testDiscretization</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="mf">0.2</span><span class="o">*</span><span class="mf">0.5</span><span class="o">**</span><span class="n">i</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xh</span><span class="p">,</span> <span class="n">fprimF</span><span class="p">,</span> <span class="s1">'ro'</span><span class="p">,</span> <span class="n">clip_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="nb">max</span><span class="p">(</span><span class="n">fprimF</span><span class="p">)])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'$x$'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Derivatives'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'Exact Derivatives'</span><span class="p">,</span><span class="s1">'Calculated Derivatives'</span><span class="p">])</span>| </pre></div><figure data-size="normal"><noscript> $h$  的减小，逐渐靠近真实值．</p><h2>小结：舍入误差 vs. 离散化误差</h2><p>我们通过下面这个例子来分析和对比这两个误差．</p><h3>例子6: 对比两个误差</h3><p>继续例子4中的函数  $f(x)=e^x$  和它的导数  $f'(x)=e^x$  ．取  $x=1$  ，分别用前面提到的三种有限微分方法求出数值导数，并与真实值比较计算出相对误差．

这里我们来观察，当  $h$  取不同值（ $10^{-1}$  至  $10^{-15}$ ）的时候，相对误差的变化情况．</p><div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">ForwardDiff</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="c1"># Forward difference</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="n">h</span>

<span class="k">def</span> <span class="nf">CentralDiff</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="c1"># Central difference</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">))</span><span class="o">/</span><span class="n">h</span><span class="o">*</span><span class="mf">0.5</span>

<span class="k">def</span> <span class="nf">FivePointsDiff</span><span class="p">(</span><span class="n">fx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
    <span class="c1"># Five points difference </span>
    <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="mi">8</span><span class="o">*</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="mi">8</span><span class="o">*</span><span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">fx</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mf">12.0</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>

<span class="c1"># choose h from 0.1 to 10^-t, t>=2</span>
<span class="n">t</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">hx</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="n">t</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># The exact derivative at x=1</span>
<span class="n">x0</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">fprimExact</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Numerical derivative using the three methods</span>
<span class="n">fprimF</span> <span class="o">=</span> <span class="n">ForwardDiff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>
<span class="n">fprimC</span> <span class="o">=</span> <span class="n">CentralDiff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>
<span class="n">fprim5</span> <span class="o">=</span> <span class="n">FivePointsDiff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>

<span class="c1"># Relative error</span>
<span class="n">felF</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span> <span class="o">-</span> <span class="n">fprimF</span><span class="p">)</span><span class="o">/</span><span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span><span class="p">)</span>
<span class="n">felC</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span> <span class="o">-</span> <span class="n">fprimC</span><span class="p">)</span><span class="o">/</span><span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span><span class="p">)</span>
<span class="n">fel5</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span> <span class="o">-</span> <span class="n">fprim5</span><span class="p">)</span><span class="o">/</span><span class="nb">abs</span><span class="p">(</span><span class="n">fprimExact</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">hx</span><span class="p">,</span> <span class="n">felF</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">hx</span><span class="p">,</span> <span class="n">felC</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">hx</span><span class="p">,</span> <span class="n">fel5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">'x'</span><span class="p">,</span> <span class="n">tight</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'Step length $h$'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Relative error'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'Forward difference'</span><span class="p">,</span><span class="s1">'Central difference'</span><span class="p">,</span> <span class="s1">'Five points difference'</span><span class="p">])</span>
<span class="o"><</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">legend</span><span class="o">.</span><span class="n">Legend</span> <span class="n">at</span> <span class="mh">0x12066aad0</span><span class="o">></span>| </pre></div><figure data-size="normal"><noscript> $h$  的不同，呈现出两种不同的特性．  </li><li>当  $h$  较大时（右半侧），误差曲线相对规则，是由离散化误差主导的． </li><li>当  $h$  较小时（左半侧），误差曲线波动较大，是由舍入误差主导．</li></ul><p><b>注</b>：舍入误差主导且随着  $h$  减小而增大的主要原因是： </p><ul><li>当  $h$  较小时，有限差分法的分子上相近的数相减会造成类似例子2和3中的舍入误差．  </li><li>由于这个例子中的  $f(x)$  在  $e$  附近，因此这个误差应为  $10^{-16}$  左右．它除以较小的  $h$  时，就会被相应的放大，当  $h$  越小，这个舍入误差越大．</li></ul><p>因此，<b>当我们使用上述方法时，需要注意，尽可能取</b>  $h$  <b>在误差曲线的右半侧，这样我们对于误差才有完全的控制．</b>

同时，我们也观察到，对于越是高阶的差分（如五点差分），它的离散化误差随  $h$  的下降速率越大，但也越早到达舍入误差的区域． 因此，当我们遇到类似问题上，应<b>选择合适阶数的有限差分方法，并根据它的特性选择适合的</b>  $h$  <b>值．并不一定是越高阶的方法越好，</b>  $h$  <b>越小越好．</b></p><p class="ztext-empty-paragraph"><br/>

本文中所用函数的完整代码见github: