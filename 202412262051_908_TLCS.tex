% 图灵测试（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Turing_test}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/3f5360e4685a515c.png}
\caption{图灵测试的“标准解释”中，C玩家（询问者）被赋予任务，试图判断哪一位玩家——A还是B——是计算机，哪一位是人类。询问者仅限于通过书面问题的回答来做出判断。[1]} \label{fig_TLCS_1}
\end{figure}
图灵测试，最初由艾伦·图灵于1949年提出，称为“模仿游戏”，是对机器是否能够表现出等同于人类的智能行为的测试，或者说是无法与人类行为区分的测试。图灵提出，测试中一位人类评估者将判断人类与机器之间的自然语言对话，机器被设计成产生类似人类的回应。评估者知道对话中的一方是机器，所有参与者都将被隔开。对话仅限于文字交流，例如使用计算机键盘和屏幕，因此测试结果不依赖于机器将文字转化为语音的能力。如果评估者无法可靠地区分机器与人类，那么机器就被认为通过了测试。测试的结果不依赖于机器是否能给出正确答案，而是看它的答案与人类回答的相似程度。由于图灵测试是对性能能力无法区分性的测试，因此其语言版本自然地推广到了所有人类的表现能力，包括语言和非语言（机器人）的表现能力。

该测试由图灵在1950年发表的论文《计算机与智能》中提出，当时他在曼彻斯特大学工作。论文开头写道：“我提议考虑这个问题，‘机器能思考吗？’”由于“思考”这一概念很难定义，图灵选择用“用另一种更相关且表达相对明确的话语替代这个问题”来描述问题。[6] 图灵以“三人游戏”的形式来描述这一问题，这个游戏称为“模仿游戏”，在这个游戏中，一位询问者通过向一位男士和一位女士提问，试图判断两位参与者的性别。图灵的新问题是：“是否存在可以在模仿游戏中表现得很好的数字计算机？”[2] 图灵认为这个问题是可以回答的。在论文的其余部分，他反驳了关于“机器能思考”这一命题的所有主要反对意见。[7]

自从图灵提出他的测试以来，它既具有深远的影响，也受到了广泛的批评，并成为人工智能哲学中的一个重要概念。[8][9] 哲学家约翰·塞尔在他的“中文房间”论证中评论了图灵测试，这一思想实验认为，无论程序如何使计算机表现得像人类，机器都无法拥有“思维”、“理解”或“意识”。塞尔批评图灵的测试，并声称它不足以检测意识的存在。
\subsection{聊天机器人}  
图灵测试后来促成了“聊天机器人”的发展，这些人工智能软件实体的唯一目的是与人进行文本聊天。今天，聊天机器人有了更广泛的定义；它是一个能够与人进行对话的计算机程序，通常通过互联网进行。OED[10][11]  
\subsubsection{ELIZA 和 PARRY}  
1966年，Joseph Weizenbaum创建了一个名为ELIZA的程序。该程序通过检查用户输入的评论中的关键词来工作。如果找到了关键词，就会应用一个规则来转换用户的评论，并返回生成的句子。如果没有找到关键词，ELIZA则会以一个通用的回答或通过重复之前的评论来回应。[12] 此外，Weizenbaum将ELIZA开发为模拟罗杰斯式心理治疗师的行为，使得ELIZA能够“自由地假设几乎对真实世界一无所知”。[13] 通过这些技术，Weizenbaum的程序能够让一些人相信他们在与一个真人对话，甚至有些人“非常难以相信ELIZA [...] 不是人类”。[13] 因此，有些人认为ELIZA是第一个能够通过图灵测试的程序，[13][14] 尽管这一观点存在很大争议（参见下文“询问者的天真”）。

1972年，Kenneth Colby创建了PARRY，一个被描述为“带有态度的ELIZA”的程序。[15] 它试图模拟偏执型精神分裂症患者的行为，采用与Weizenbaum类似（但更先进）的方法。为了验证该工作，PARRY在1970年代早期通过图灵测试的变体进行了测试。一个由经验丰富的精神科医生组成的小组分析了通过电传打字机传输的真实病人与运行PARRY的计算机的对话。另一个由33名精神科医生组成的小组则查看了对话记录。随后，这两个小组被要求识别哪些“病人”是人类，哪些是计算机程序。[16] 精神科医生们仅有52\%的正确识别率——这一数据与随机猜测相符。[16]
\subsubsection{尤金·古斯特曼 (Eugene Goostman)}  
2001年，在俄罗斯圣彼得堡，由三位程序员——俄罗斯出生的弗拉基米尔·维谢洛夫、乌克兰出生的尤金·德门琴科和俄罗斯出生的谢尔盖·乌拉森——开发了一个名为“尤金·古斯特曼”的聊天机器人。2014年7月7日，它成为了第一个看似通过图灵测试的聊天机器人，在英国雷丁大学举办的纪念阿兰·图灵60周年忌日的活动中，三分之一的评委认为古斯特曼是人类；活动组织者凯文·沃里克认为它通过了图灵测试。古斯特曼被描绘为一位来自乌克兰敖德萨的13岁男孩，拥有一只豚鼠宠物和一位妇科医生父亲。选择这个年龄是故意的，目的是让与他“对话”的人原谅他回答中的小语法错误。[10][17][18]  
\subsubsection{Google LaMDA}  
2022年6月，谷歌的LaMDA（对话应用的语言模型）聊天机器人因被声称具备意识而广泛报道。最初在《经济学人》的一篇文章中，谷歌研究员布莱斯·阿圭拉·亚卡斯表示，LaMDA展示了对社会关系的某种理解。[19] 几天后，谷歌工程师布莱克·莱莫因在《华盛顿邮报》的采访中声称，LaMDA已具备意识。莱莫因因内部提出这一观点而被谷歌停职。阿圭拉·亚卡斯（谷歌副总裁）和詹·吉奈（负责创新的负责人）调查了这一说法，但驳回了它们。[20] 莱莫因的主张遭到该领域其他专家的普遍反对，指出一个看似模仿人类对话的语言模型，并不意味着其背后存在任何智能，[21] 尽管它似乎通过了图灵测试。关于LaMDA是否已经达到意识的讨论在支持和反对双方的推动下，激起了社交媒体平台上的广泛讨论，包括对“意识”意义的定义，以及什么才是“人类”的问题。
\subsubsection{ChatGPT}   
OpenAI发布的聊天机器人ChatGPT，基于GPT-3.5和GPT-4大语言模型，于2022年11月推出。Celeste Biever在《自然》杂志的文章中写道，“ChatGPT突破了图灵测试”。[22] 斯坦福大学的研究人员报告称，ChatGPT通过了图灵测试；他们发现ChatGPT-4“通过了严格的图灵测试，偏离普通人类行为，主要是表现得更加合作”。[23][24]
\subsubsection{虚拟助手}  
虚拟助手也是基于人工智能的软件代理，旨在通过文本或语音命令回应指令或问题并执行任务，因此它们自然也包含了聊天机器人的功能。面向消费者的知名虚拟助手包括苹果的Siri、亚马逊的Alexa、谷歌助手、三星的Bixby和微软的Copilot。[25][26][27][28]
\subsubsection{恶意软件}  
这些程序的版本仍然能够欺骗用户。“CyberLover”是一个恶意软件程序，通过说服用户“透露个人身份信息或引导他们访问将恶意内容传送到计算机的网站”来攻击互联网用户。[29] 该程序已成为一种“情人节风险”，通过与“寻求在线关系”的人进行调情，收集他们的个人数据。[30]
\subsection{历史}  
\subsubsection{哲学背景}
机器是否能够思考的问题有着悠久的历史，深深植根于心灵的二元论和物质主义观点的区别中。勒内·笛卡尔在1637年的《方法谈》中预示了图灵测试的某些方面，他写道：

[H]ow many different automata or moving machines could be made by the industry of man ... For we can easily understand a machine's being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on. But it never happens that it arranges its speech in various ways, in order to reply appropriately to everything that may be said in its presence, as even the lowest type of man can do.[31]

笛卡尔在这里指出，自动机能够对人类的互动作出反应，但他认为这些自动机无法像任何人类那样恰当地回应其面前所说的任何话。因此，笛卡尔通过将适当的语言反应的不足定义为区分人类和自动机的标准，预示了图灵测试。笛卡尔并未考虑到未来的自动机可能克服这种不足，因此他并未提出图灵测试，即使他预示了其概念框架和标准。

丹尼斯·狄德罗在1746年的《哲学思考》一书中提出了一个图灵测试标准，尽管其隐含的限制假设是参与者必须是自然的有生命的存在，而非考虑人工创造的物体：

如果他们发现一只能够回答所有问题的鹦鹉，我会毫不犹豫地认为它是一个智能生物。

这并不意味着他同意这个观点，而是表明这已经是当时物质主义者普遍的论点。

根据二元论，心灵是非物质的（或至少具有非物质的特性），因此无法用纯粹的物理术语解释。而根据物质主义，心灵可以用物理的方式来解释，这为人工产生的心灵打开了可能性。

1936年，哲学家阿尔弗雷德·艾耶考虑了标准的哲学问题——其他心灵的问题：我们如何知道其他人是否拥有与我们相同的意识体验？在他的书《语言、真理与逻辑》中，艾耶提出了一种区分有意识的人和无意识机器的协议：“我只能通过一个经验测试来断言一个看似有意识的物体实际上并非一个有意识的存在，而只是一个傀儡或机器，这个测试通过判断是否具备意识来确定。”[34]（这一建议与图灵测试非常相似，但不确定艾耶的哲学经典是否为图灵所熟知。）换句话说，如果一个物体未能通过意识测试，则它不是有意识的。
\subsubsection{文化背景} 
图灵测试的一个初步概念出现在乔纳森·斯威夫特1726年出版的小说《格列佛游记》中。[35][36] 当格列佛被带到布罗卑丁纳国的国王面前时，国王最初认为格列佛可能是“某种钟表机械（在那个国家已经达到了极高的完美程度），由某位聪明的艺术家设计”。即使他听到格列佛说话，国王仍然怀疑格列佛是否被教会了“某些词语”，以便让他“以更高的价格出售”。格列佛告诉国王，直到“他向我提出了几个其他问题，并且仍然得到了理性的回答”，国王才确信格列佛不是一台机器。[37]

到1940年代，科幻小说中已经形成了通过人类判断计算机或外星人是否智能的传统，图灵很可能会意识到这些作品。[38] 斯坦利·G·温鲍姆的《火星奥德赛》（1934年）就提供了一个例子，展示了这些测试如何变得复杂。[38]

早期的机器或自动装置试图伪装成人类的例子包括古希腊神话中的皮格马利翁，他创造了一个女性雕像，由爱神阿佛洛狄忒赋予生命；卡洛·科洛迪的小说《木偶奇遇记》，讲述了一个渴望变成真实男孩的木偶；以及E·T·A·霍夫曼的1816年故事《沙人》，其中主人公爱上了一个自动人。在这些例子中，人们被那些能够在一定程度上伪装成人类的人工存在所愚弄。[39]