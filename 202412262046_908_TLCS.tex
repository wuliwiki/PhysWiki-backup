% 图灵测试（综述）
% license CCBYSA3
% type Wiki

本文根据 CC-BY-SA 协议转载翻译自维基百科\href{https://en.wikipedia.org/wiki/Turing_test}{相关文章}。

\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{./figures/3f5360e4685a515c.png}
\caption{图灵测试的“标准解释”中，C玩家（询问者）被赋予任务，试图判断哪一位玩家——A还是B——是计算机，哪一位是人类。询问者仅限于通过书面问题的回答来做出判断。[1]} \label{fig_TLCS_1}
\end{figure}
图灵测试，最初由艾伦·图灵于1949年提出，称为“模仿游戏”，是对机器是否能够表现出等同于人类的智能行为的测试，或者说是无法与人类行为区分的测试。图灵提出，测试中一位人类评估者将判断人类与机器之间的自然语言对话，机器被设计成产生类似人类的回应。评估者知道对话中的一方是机器，所有参与者都将被隔开。对话仅限于文字交流，例如使用计算机键盘和屏幕，因此测试结果不依赖于机器将文字转化为语音的能力。如果评估者无法可靠地区分机器与人类，那么机器就被认为通过了测试。测试的结果不依赖于机器是否能给出正确答案，而是看它的答案与人类回答的相似程度。由于图灵测试是对性能能力无法区分性的测试，因此其语言版本自然地推广到了所有人类的表现能力，包括语言和非语言（机器人）的表现能力。

该测试由图灵在1950年发表的论文《计算机与智能》中提出，当时他在曼彻斯特大学工作。论文开头写道：“我提议考虑这个问题，‘机器能思考吗？’”由于“思考”这一概念很难定义，图灵选择用“用另一种更相关且表达相对明确的话语替代这个问题”来描述问题。[6] 图灵以“三人游戏”的形式来描述这一问题，这个游戏称为“模仿游戏”，在这个游戏中，一位询问者通过向一位男士和一位女士提问，试图判断两位参与者的性别。图灵的新问题是：“是否存在可以在模仿游戏中表现得很好的数字计算机？”[2] 图灵认为这个问题是可以回答的。在论文的其余部分，他反驳了关于“机器能思考”这一命题的所有主要反对意见。[7]

自从图灵提出他的测试以来，它既具有深远的影响，也受到了广泛的批评，并成为人工智能哲学中的一个重要概念。[8][9] 哲学家约翰·塞尔在他的“中文房间”论证中评论了图灵测试，这一思想实验认为，无论程序如何使计算机表现得像人类，机器都无法拥有“思维”、“理解”或“意识”。塞尔批评图灵的测试，并声称它不足以检测意识的存在。
\subsection{聊天机器人}  
图灵测试后来促成了“聊天机器人”的发展，这些人工智能软件实体的唯一目的是与人进行文本聊天。今天，聊天机器人有了更广泛的定义；它是一个能够与人进行对话的计算机程序，通常通过互联网进行。OED[10][11]  
\subsubsection{ELIZA 和 PARRY}  
1966年，Joseph Weizenbaum创建了一个名为ELIZA的程序。该程序通过检查用户输入的评论中的关键词来工作。如果找到了关键词，就会应用一个规则来转换用户的评论，并返回生成的句子。如果没有找到关键词，ELIZA则会以一个通用的回答或通过重复之前的评论来回应。[12] 此外，Weizenbaum将ELIZA开发为模拟罗杰斯式心理治疗师的行为，使得ELIZA能够“自由地假设几乎对真实世界一无所知”。[13] 通过这些技术，Weizenbaum的程序能够让一些人相信他们在与一个真人对话，甚至有些人“非常难以相信ELIZA [...] 不是人类”。[13] 因此，有些人认为ELIZA是第一个能够通过图灵测试的程序，[13][14] 尽管这一观点存在很大争议（参见下文“询问者的天真”）。

1972年，Kenneth Colby创建了PARRY，一个被描述为“带有态度的ELIZA”的程序。[15] 它试图模拟偏执型精神分裂症患者的行为，采用与Weizenbaum类似（但更先进）的方法。为了验证该工作，PARRY在1970年代早期通过图灵测试的变体进行了测试。一个由经验丰富的精神科医生组成的小组分析了通过电传打字机传输的真实病人与运行PARRY的计算机的对话。另一个由33名精神科医生组成的小组则查看了对话记录。随后，这两个小组被要求识别哪些“病人”是人类，哪些是计算机程序。[16] 精神科医生们仅有52\%的正确识别率——这一数据与随机猜测相符。[16]
\subsubsection{尤金·古斯特曼 (Eugene Goostman)}  
2001年，在俄罗斯圣彼得堡，由三位程序员——俄罗斯出生的弗拉基米尔·维谢洛夫、乌克兰出生的尤金·德门琴科和俄罗斯出生的谢尔盖·乌拉森——开发了一个名为“尤金·古斯特曼”的聊天机器人。2014年7月7日，它成为了第一个看似通过图灵测试的聊天机器人，在英国雷丁大学举办的纪念阿兰·图灵60周年忌日的活动中，三分之一的评委认为古斯特曼是人类；活动组织者凯文·沃里克认为它通过了图灵测试。古斯特曼被描绘为一位来自乌克兰敖德萨的13岁男孩，拥有一只豚鼠宠物和一位妇科医生父亲。选择这个年龄是故意的，目的是让与他“对话”的人原谅他回答中的小语法错误。[10][17][18]  
\subsubsection{Google LaMDA}  
2022年6月，谷歌的LaMDA（对话应用的语言模型）聊天机器人因被声称具备意识而广泛报道。最初在《经济学人》的一篇文章中，谷歌研究员布莱斯·阿圭拉·亚卡斯表示，LaMDA展示了对社会关系的某种理解。[19] 几天后，谷歌工程师布莱克·莱莫因在《华盛顿邮报》的采访中声称，LaMDA已具备意识。莱莫因因内部提出这一观点而被谷歌停职。阿圭拉·亚卡斯（谷歌副总裁）和詹·吉奈（负责创新的负责人）调查了这一说法，但驳回了它们。[20] 莱莫因的主张遭到该领域其他专家的普遍反对，指出一个看似模仿人类对话的语言模型，并不意味着其背后存在任何智能，[21] 尽管它似乎通过了图灵测试。关于LaMDA是否已经达到意识的讨论在支持和反对双方的推动下，激起了社交媒体平台上的广泛讨论，包括对“意识”意义的定义，以及什么才是“人类”的问题。
\subsubsection{ChatGPT}   
OpenAI发布的聊天机器人ChatGPT，基于GPT-3.5和GPT-4大语言模型，于2022年11月推出。Celeste Biever在《自然》杂志的文章中写道，“ChatGPT突破了图灵测试”。[22] 斯坦福大学的研究人员报告称，ChatGPT通过了图灵测试；他们发现ChatGPT-4“通过了严格的图灵测试，偏离普通人类行为，主要是表现得更加合作”。[23][24]
\subsubsection{虚拟助手}  
虚拟助手也是基于人工智能的软件代理，旨在通过文本或语音命令回应指令或问题并执行任务，因此它们自然也包含了聊天机器人的功能。面向消费者的知名虚拟助手包括苹果的Siri、亚马逊的Alexa、谷歌助手、三星的Bixby和微软的Copilot。[25][26][27][28]
\subsubsection{恶意软件}  
这些程序的版本仍然能够欺骗用户。“CyberLover”是一个恶意软件程序，通过说服用户“透露个人身份信息或引导他们访问将恶意内容传送到计算机的网站”来攻击互联网用户。[29] 该程序已成为一种“情人节风险”，通过与“寻求在线关系”的人进行调情，收集他们的个人数据。[30]